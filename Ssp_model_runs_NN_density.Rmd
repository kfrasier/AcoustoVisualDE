---
title: 'Stenellid dolphin habitat models'
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    theme: spacelab
    fig_caption: true 

---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages, echo = FALSE, message = FALSE, warning = FALSE}
library(rgdal)
library(raster)
library(ggplot2)
library(rgeos)
library(mapview)
library(leaflet)
library(psych)
library(broom)
library(plotrix)
library(magrittr)
library(colorRamps)
library(lubridate)
library(HabitatProject)
library(nnet)
library(caret)
source('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/HabitatProject/R/multiplot.R')
options(stringsAsFactors = FALSE)
# load some preferences
load('E:/NASData/ModelData/Ssp/setup_info_Ssp.Rdata')
load('E:/NASData/ModelData/Ssp/SspMergedData.Rdata')
outDir <- file.path('E:/NASData/ModelData',SP,'/')

```
<br>

# I. Exploratory analysis

## Data Inputs

The visual data goes back to 1992, but as shown in the figure below, many predictor variables are only available starting in 2003, therefore earlier visual data is currently excluded from further analyses. 

Note: Future work could use monthly climatologies (averages) so that older sightings data could be used. Some dynamic drivers like eddy and front locations would not be able to be considered using that approach.

```{r Missing data, echo = FALSE}
covarList<-names(mergedSegments[c(2,5:length(mergedSegments))])

percFilled <- plot.missingdata(mergedSegments,covarList,paste0(outDir,'AcousticAndVisual_',SP)) 
percFilled <- plot.missingdata(AcOnlySegments,covarList,paste0(outDir,'AcousticOnly_',SP)) 
percFilled <- plot.missingdata(VisOnlySegments,covarList,paste0(outDir,'VisualOnly_',SP)) 
```

Visual data predictor variable availability: 
![](E:/NASData/ModelData/Ssp/VisualOnly_Ssp_missingData.png)
<br> 


### Testing and Training Sets

The data are split into training and testing sets. In this case, data from 2009 and 2013 are used for testing. Only observations post-2003 are used for modeling due to covariate limitations.

```{r test train split, echo = FALSE}
# If you decide from the missing data plots that you want to restrict years going forward:
yearListIdx = as.numeric(format(mergedSegments$date,"%Y"))
yearListIdx_AcOnly = as.numeric(format(AcOnlySegments$date,"%Y"))
yearListIdx_VisOnly = as.numeric(format(VisOnlySegments$date,"%Y"))

keepDates.train <- which(yearListIdx != 2009 & yearListIdx >= 2003 & yearListIdx <= 2012)
keepDates.test <- which(yearListIdx == 2009 | yearListIdx == 2013)
keepDates_AcOnly.train <- which(yearListIdx_AcOnly != 2009 & yearListIdx_AcOnly >= 2003 & yearListIdx_AcOnly <= 2012)
keepDates_AcOnly.test <- which(yearListIdx_AcOnly == 2009 | yearListIdx_AcOnly == 2013)
keepDatesVisOnly.train <- which(yearListIdx_VisOnly != 2009 & yearListIdx_VisOnly >= 2003)
keepDatesVisOnly.test <- which(yearListIdx_VisOnly == 2009)

mergedTrain.set<- mergedSegments[keepDates.train,]
Train_AcOnly.set <- AcOnlySegments[keepDates_AcOnly.train,]
Train_VisOnly.set<- VisOnlySegments[keepDatesVisOnly.train,]

mergedTest.set<- mergedSegments[keepDates.test,]
Test_AcOnly.set<- AcOnlySegments[keepDates_AcOnly.test,]
Test_VisOnly.set<- VisOnlySegments[keepDatesVisOnly.test,]
```



### Preliminary Mapping

The visual data selected for modeling are displayed on the map below. Data from 2009 were held back for testing. Blue markers indicate HARP locations.

```{r map inputs, warning = FALSE, echo = FALSE}
# Get test visual sightings
sightingsTrain <- Train_VisOnly.set[Train_VisOnly.set$Density>0,c('lat','long','date')]

sightingsTest <- Test_VisOnly.set[Test_VisOnly.set$Density>0,c('lat','long','date')]
HARPsites <- unique(Train_AcOnly.set[c('lat','long')])
pal <-colorFactor(palette = "RdYlGn", 
                  domain = c(2003,2004,2009,2012,2014))
  
map1 <- leaflet() %>%  setView(lng = -89.4, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addCircleMarkers(data = sightingsTrain, lng = ~ long, lat = ~ lat,color = ~pal(year(date)),
                 stroke = TRUE, fillOpacity = 0.8, group = 'Training Set',radius = 4)%>%
  addCircleMarkers(data = sightingsTest, lng = ~ long, lat = ~ lat,color = ~pal(year(date)),
                 stroke = TRUE, fillOpacity = 0.8, group = 'Test Set',radius = 4)%>%
  addMarkers(data = HARPsites, lng = ~ long, lat = ~ lat) %>%
  addLegend(pal = pal,values = c(2003,2004,2009,2012,2014),title = 'Year') 

map1
```
<br>

The time series below show the acoustic data used for modeling. Data from 2011 and 2012 used for training, and 2013 data is held back for testing. These density magnitudes are very preliminary,and models only used presence absence data.


```{r plot timeseries, message = FALSE, echo = FALSE}
plot.timeseries(siteList,outDir,AcOnlySegments)
```



![](E:/NASData/ModelData/Ssp/Ssp_Timeseries_Site_MC.png)
![](E:/NASData/ModelData/Ssp/Ssp_Timeseries_Site_GC.png)
![](E:/NASData/ModelData/Ssp/Ssp_Timeseries_Site_DT.png)
![](E:/NASData/ModelData/Ssp/Ssp_Timeseries_Site_DC.png)

![](E:/NASData/ModelData/Ssp/Ssp_Timeseries_Site_MP.png)
<br> 

## Examine Covariates

```{r remove outliers, message = FALSE, results = 'hide', echo = FALSE}
# Replace extreme outliers (bad data) with NaNs.
outlierList <-which(mergedSegments$CHL< -10)
mergedSegments$CHL[outlierList] <- NaN 
outlierList <-which(mergedSegments$FrontDist_Cayula>800000)
mergedSegments$FrontDist_Cayula[outlierList] <- NaN 
outlierList <-which(mergedSegments$Density>10000)
mergedSegments$Density[outlierList] <- NaN 

outlierList <-which(AcOnlySegments$CHL< -10)
AcOnlySegments$CHL[outlierList] <- NaN 
outlierList <-which(AcOnlySegments$FrontDist_Cayula>800000)
AcOnlySegments$FrontDist_Cayula[outlierList] <- NaN 
outlierList <-which(AcOnlySegments$Density>10000)
AcOnlySegments$Density[outlierList] <- NaN 

outlierList <-which(VisOnlySegments$CHL<  -10)
VisOnlySegments$CHL[outlierList] <- NaN 
outlierList <-which(VisOnlySegments$FrontDist_Cayula>800000)
VisOnlySegments$FrontDist_Cayula[outlierList] <- NaN 
outlierList <-which(VisOnlySegments$Density>10000)
VisOnlySegments$Density[outlierList] <- NaN 
```


### Check Covariate Distributions

Covariates have different distributions across the observations. 
Here are the distributions of covariates from the acoustic observations:

```{r dot plots, eval = TRUE, message = FALSE, results = 'hide', echo = FALSE}
plot.cleveland(mergedTrain.set,covarList,FALSE,paste0(outDir,'AcousticAndVisual_',SP))
plot.cleveland(Train_AcOnly.set,covarList,FALSE,paste0(outDir,'AcousticOnly_',SP))
plot.cleveland(Train_VisOnly.set,covarList,FALSE,paste0(outDir,'VisualOnly_',SP))
```

![](E:/NASData/ModelData/Ssp/AcousticOnly_Ssp_clevelandDots_noTransform.png)


<br>


Here are the distributions of covariates from the visual observations:
![](E:/NASData/ModelData/Ssp/VisualOnly_Ssp_clevelandDots_noTransform.png)

<br>

Some of these covariates are more or less interrelated. HYCOM estimates of salinity at the surface (HYCOM_SALIN_0) and at 100m (HYCOM_SALIN_100) are very similar, so I selected surface salinity for simplicity. HYCOM current and upwelling estimates at 100m were also removed (HYCOM_MAG_100,HYCOM_UPVEL_100). HYCOM current direction is site specific in the acoustic data, so it was excluded for now. 


Remaining correlations are examined in the figure below. Numbers closer to 1 above the diagonal in the figure below represent correlation coefficients. Highly correlated covariates should not be used together in the same model. Day of year was excluded to avoid artifacts associated with the temporal differences of the datasets (Acoustic data are year-round, and visual data are collected in spring/summer).

```{r correlation plots, eval = TRUE, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
covarList2 <- c("SST","SSH","CHL","HYCOM_MLD",
                "HYCOM_SALIN_0","HYCOM_DIR_0",
                "HYCOM_MAG_0",
                "HYCOM_UPVEL_50","FrontDist_Cayula",
                "EddyDist","Neg_EddyDist","Pos_EddyDist",
                "DayOfYear","fac1","fac2")

# restrict covariates again to limited set
mergedTrain.set2<- mergedTrain.set[,covarList2]
mergedTest.set2<- mergedTest.set[,covarList2]
Train_AcOnly.set2<- Train_AcOnly.set[,covarList2]
Test_AcOnly.set2<- Test_AcOnly.set[,covarList2]
Train_VisOnly.set2<- Train_VisOnly.set[,covarList2]
Test_VisOnly.set2<- Test_VisOnly.set[,covarList2]

# without transform
png(paste(outDir,SP,'_correlations_noTransform.png',sep=''), width = 2000, height = 1600)
pairs.panels(mergedTrain.set2[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off()
png(paste(outDir,SP,'_correlations_noTransform_AcOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(Train_AcOnly.set2[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off()
png(paste(outDir,SP,'_correlations_noTransform_visOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(Train_VisOnly.set2[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off()

```
![](E:/NASData/ModelData/Ssp/Ssp_correlations_noTransform.png)

<br>

### Transform Predictor Variables

Some variables, including chlorophyll, current magnitude, mixed layer depth and distance to fronts are highly skewed and were log-transformed.

```{r transform covars, message = FALSE, results = 'hide', echo = FALSE}
# covarList2 <- c("SST","SSH","CHL","HYCOM_MLD",
#                 "HYCOM_SALIN_0","HYCOM_DIR_0",
#                 "HYCOM_MAG_0",
#                 "HYCOM_UPVEL_50","FrontDist_Cayula",
#                 "EddyDist","Neg_EddyDist", "PosEddyDist",
#                 "DayOfYear","fac1","fac2")

transformList <- c("none","none","log10","log10",
                   "none","none",
                   "log10",
                   "none","log10",
                   "none","none","none",
                   "none","none","none")

transformedCovars.train <-
  transform.covars(mergedTrain.set2,covarList2,transformList)
transformedCovars.test <- 
  transform.covars(mergedTest.set2,covarList2,transformList)

transformedCovars_AcOnly.train <-
  transform.covars(Train_AcOnly.set2,covarList2,transformList)
transformedCovars_AcOnly.test <-
  transform.covars(Test_AcOnly.set2,covarList2,transformList)
transformedCovars_VisOnly.train <-
  transform.covars(Train_VisOnly.set2,covarList2,transformList)
transformedCovars_VisOnly.test <-
  transform.covars(Test_VisOnly.set2,covarList2,transformList)

# Generate correlation plots with transform
png(paste(outDir,SP,'_correlations_withTransform.png',sep=''), width = 2000, height = 1600)
pairs.panels(transformedCovars.train[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off() 
png(paste(outDir,SP,'_correlations_withTransform_AcOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(transformedCovars_AcOnly.train[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off() 
png(paste(outDir,SP,'_correlations_withTransform_visOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(transformedCovars_VisOnly.train[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off() 

```


```{r transformed dot plots, eval = TRUE, message = FALSE, results = 'hide', echo = FALSE}
# Plotting the transformed variables: 
plotCols = colnames(transformedCovars.train)[1:(length(covarList2)-2)]
plot.cleveland(transformedCovars.train,
               plotCols,TRUE,paste0(outDir,'AcousticAndVisual_',SP))
plot.cleveland(transformedCovars_AcOnly.train,
               plotCols,TRUE,paste0(outDir,'AcousticOnly_',SP))
plot.cleveland(transformedCovars_VisOnly.train,
               plotCols,TRUE,paste0(outDir,'VisualOnly_',SP))

```
<br>

Below, the two sets of covariates have been combined and transformed. 
![](E:/NASData/ModelData/Ssp/AcousticAndVisual_Ssp_clevelandDots_withTransform.png)

<br>

### Check Predictors

To get an idea of the basic predictive power of these covariates, we can look at presence/absence relative to each variable. This also provides an opportunity to look at the range of values observed for each covariate in the visual and acoustic datasets. In the plots below dotted lines indicate the distribution of each covariate when animals were present, and solid lines indicate the distribution when animals were absent. Note that these plots do not account for effort.

```{r presence absence histograms, eval = TRUE, message = FALSE, results = 'hide', echo = FALSE}
plot.covarDensity(transformedCovars.train[,1:(length(transformedCovars.train)-2)],
                  colnames(transformedCovars.train[,1:(length(transformedCovars.train)-4)]),
                  mergedTrain.set$Density,paste0(outDir,'Both_',SP))

plot.covarDensity(transformedCovars_AcOnly.train[,1:(length(transformedCovars_AcOnly.train)-2)],
                   colnames(transformedCovars_AcOnly.train[1:(length(transformedCovars_AcOnly.train)-4)]),
                  Train_AcOnly.set$Density,paste0(outDir,'AcousticOnly_',SP))		

plot.covarDensity(transformedCovars_VisOnly.train[,1:(length(transformedCovars_VisOnly.train)-2)],
                  colnames(transformedCovars_VisOnly.train[,1:(length(transformedCovars_VisOnly.train)-4)]),
                  Train_VisOnly.set$Density,paste0(outDir,'VisualOnly_',SP))
```

<br> 
Acoustic kernel densities:

![](E:/NASData/ModelData/Ssp/AcousticOnly_Ssp_density_pres_abs.png)

<br>  
Visual kernel densities:

![](E:/NASData/ModelData/Ssp/VisualOnly_Ssp_density_pres_abs.png)

<br> 


### Estimate Relative Weights


<br>

Currently, weights are based on the following logic: 

* Acoustic data represent presence in 1 day bins, 

* Acoustic data have a trucation distance  of 1.3km for Stenella spp. (95% of detections occur within this range), for a total monitoring area of $(1.3 km)^{2} \pi = 11.3 km^{2}$, 

* Visual data represent presence during ~10 km transect segments traveling at ~10 knots or ~18.5km/hr. Therefore each visual datapoint represents ~0.54 hours of effort. 

* Visual trucation distance for Stenella spp. is estimated as 5.1 km (see figure below) from these data. ESW is multiplied by transect segment length (usually ~10km) and doubled to estimate total area swept.


<br>  

\[\text{Acoustic to Visual ratio} = \frac{24 hrs \cdot (1.3 km)^{2} \pi}{(\text{Segment length}/18.52 km/hr) \cdot 5.1 km \cdot \text{Segment length} \cdot 2} = 127.42/55.08 \approx 2.3:1
\]

<br> 

Best visual detection probability model:

![](E:/NASData/ModelData/Ssp/SspsightwTrunc_GU.png)

<br> 

Zeros in visual dataset are down-weighted by g0 for this species, as estimated by Palka 2007.


<br> 

# II. Model Fitting

Models were fit using avNNet from the caret package in R. 

```{r load starting data, echo = FALSE} 
weeklyOccurrenceFile = paste0(outDir,'ALLSITES_weeklyPOccurrence_Ssp_jahStart.csv')
pOccur <- read.csv(weeklyOccurrenceFile, header = TRUE,na.strings=c('',' ','NA','NaN'))
```

<br>

```{r model setup, echo = FALSE} 
# Run & evaluate models
yAcOnly_TF <- Train_AcOnly.set$Density >0
yVisOnly_TF <- Train_VisOnly.set$Density >0
y_TF <- mergedTrain.set$Density>0

 # initialize empty structure for model storage
nn_AcOnly<-NULL
nn_VisOnly<-NULL
nn_Joint<-NULL

 # initialize empty structure for model storage
MSE.nn_AcOnly<-NULL
MSE.nn_VisOnly<-NULL
MSE.nn_Joint<-NULL


# make some factors and calculate introduce column of g0 weights
fac3 <- array(data = NA, dim = c(length(transformedCovars.train$fac1),1))
fac4 <- array(data = NA, dim = c(length(transformedCovars.train$fac1),1))
joint_train_weightsG0<- array(data = 1, dim = c(length(transformedCovars.train$fac1),1))

for (iFac in 1:length(transformedCovars.train$fac1)) {
  if (!is.na(transformedCovars.train$fac1[iFac])){
    if (transformedCovars.train$fac1[iFac]>5) {
      fac3[iFac,1] <- 1
      fac4[iFac,1] <- 1
      if (mergedTrain.set$Density[iFac]==0){
        # if it's visual data and it's a zero, adjust by g0 ie, only a X% chance it was a true zero.
        joint_train_weightsG0[iFac,1] <- visG0
      }
    } else {
      fac3[iFac,1] <-  0
      fac4[iFac,1] <- transformedCovars.train$fac1[iFac]+1
    }
  }
}
transformedCovars.train$fac3<-fac3
transformedCovars.train$fac4<-fac4

VisOnly.train_weightsG0<- array(data = 1, dim = c(length(transformedCovars_VisOnly.train$fac1),1))
for (iFac in 1:length(transformedCovars_VisOnly.train$fac1)) {
  if (Train_VisOnly.set$Density[iFac]==0){
    # if it's visual data and it's a zero, adjust by g0 ie, only a X% chance it was a true zero.
    VisOnly.train_weightsG0[iFac,1] <- visG0
  }
}


transformedCovars_AcOnly.train$yAcOnly_TF<-yAcOnly_TF*1
transformedCovars_VisOnly.train$yVisOnly_TF<-yVisOnly_TF*1
transformedCovars.train$y_TF<-y_TF*1

transformedCovars_AcOnly.test$yAcOnly_TF<-(Test_AcOnly.set$Density >0)*1
transformedCovars_VisOnly.test$yVisOnly_TF<-(Test_VisOnly.set$Density >0)*1
transformedCovars.test$y_TF<- (mergedTest.set$Density>0)*1


transformedCovars_AcOnly.train$yAcOnly<-Train_AcOnly.set$Density
transformedCovars_VisOnly.train$yVisOnly<-Train_VisOnly.set$Density
transformedCovars.train$y<-mergedTrain.set$Density

transformedCovars_AcOnly.test$yAcOnly<-Test_AcOnly.set$Density
transformedCovars_VisOnly.test$yVisOnly<-Test_VisOnly.set$Density
transformedCovars.test$y<-mergedTest.set$Density

# Remove NaNs
goodData_Ac <- which(!is.na(rowSums(transformedCovars_AcOnly.train)))
AcOnly.train.NoNa <- transformedCovars_AcOnly.train[goodData_Ac,]

goodData_Vis <- which(!is.na(rowSums(transformedCovars_VisOnly.train)))
VisOnly.train.NoNa <- transformedCovars_VisOnly.train[goodData_Vis,]

goodData_Joint <- which(!is.na(rowSums(transformedCovars.train)))
Joint.train.NoNa <- transformedCovars.train[goodData_Joint,]


goodData_Ac_test <- which(!is.na(rowSums(transformedCovars_AcOnly.test)))
AcOnly.test.NoNa <- transformedCovars_AcOnly.test[goodData_Ac_test,]

goodData_Vis_test <- which(!is.na(rowSums(transformedCovars_VisOnly.test)))
VisOnly.test.NoNa <- transformedCovars_VisOnly.test[goodData_Vis_test,]

goodData_Joint_test <- which(!is.na(rowSums(transformedCovars.test)))
Joint.test.NoNa <- transformedCovars.test[goodData_Joint_test,]

```

```{r Scale all the data, echo = FALSE}
# NNs don't do well with unscaled data. Scale it and then unscale it at the end.

# Scale Ac only training data for the NN
covars_AcOnly_max.train <- apply(AcOnly.train.NoNa, 2, max, na.rm = TRUE)
covars_AcOnly_min.train <- apply(AcOnly.train.NoNa, 2, min, na.rm = TRUE)
AcOnly_train_scaled <- as.data.frame(scale(AcOnly.train.NoNa, 
                          center = covars_AcOnly_min.train, 
                          scale = covars_AcOnly_max.train-covars_AcOnly_min.train))
covars_AcOnly_max.train_df<- data.frame(as.list(covars_AcOnly_max.train))
covars_AcOnly_min.train_df<- data.frame(as.list(covars_AcOnly_min.train))

# Scale Vis only training data for the NN
covars_VisOnly_max.train <- apply(VisOnly.train.NoNa, 2, max, na.rm = TRUE) 
covars_VisOnly_min.train <- apply(VisOnly.train.NoNa, 2, min, na.rm = TRUE)
VisOnly_train_scaled <- as.data.frame(scale(VisOnly.train.NoNa, 
                            center = covars_VisOnly_min.train, 
                            scale = covars_VisOnly_max.train-covars_VisOnly_min.train))
# Add G0 here because you don't want it to be scaled.
VisOnly_train_scaled$weightsG0<-VisOnly.train_weightsG0[goodData_Vis]*
      (Train_VisOnly.set$Weight[goodData_Vis]/
      max(Train_VisOnly.set$Weight[goodData_Vis]))
# It's useful to have a dataframe version of this.
covars_VisOnly_max.train_df<- data.frame(as.list(covars_VisOnly_max.train))
covars_VisOnly_min.train_df<- data.frame(as.list(covars_VisOnly_min.train))

# Scale Joint training data for the NN
covars_Joint_max.train <- apply(Joint.train.NoNa, 2, max, na.rm = TRUE) 
covars_Joint_min.train <- apply(Joint.train.NoNa, 2, min, na.rm = TRUE)
Joint_train_scaled <- as.data.frame(scale(Joint.train.NoNa, 
                        center = covars_Joint_min.train, 
                        scale = covars_Joint_max.train-covars_Joint_min.train))
Joint_train_scaled$weightsG0 <-joint_train_weightsG0[goodData_Joint]*
                                (mergedTrain.set$Weight[goodData_Joint]/
                                max(mergedTrain.set$Weight[goodData_Joint]))
covars_Joint_max.train_df<- data.frame(as.list(covars_Joint_max.train))
covars_Joint_min.train_df<- data.frame(as.list(covars_Joint_min.train))

# Scale Ac only test data for the NN
covars_AcOnly_max.test <- apply(AcOnly.test.NoNa, 2, max, na.rm = TRUE) 
covars_AcOnly_min.test <- apply(AcOnly.test.NoNa, 2, min, na.rm = TRUE)
AcOnly_test_scaled <- as.data.frame(scale(AcOnly.test.NoNa, 
                       center = covars_AcOnly_min.test,
                       scale = covars_AcOnly_max.test-covars_AcOnly_min.test))
covars_AcOnly_max.test_df<- data.frame(as.list(covars_AcOnly_max.test))
covars_AcOnly_min.test_df<- data.frame(as.list(covars_AcOnly_min.test))

# Scale Vis only test data for the NN
covars_VisOnly_max.test <- apply(VisOnly.test.NoNa, 2, max, na.rm = TRUE) 
covars_VisOnly_min.test <- apply(VisOnly.test.NoNa, 2, min, na.rm = TRUE)
VisOnly_test_scaled <- as.data.frame(scale(VisOnly.test.NoNa, 
                         center = covars_VisOnly_min.test, 
                         scale = covars_VisOnly_max.test-covars_VisOnly_min.test))
covars_VisOnly_max.test_df<- data.frame(as.list(covars_VisOnly_max.test))
covars_VisOnly_min.test_df<- data.frame(as.list(covars_VisOnly_min.test))

# Scale Joint test data for the NN
covars_Joint_max.test <- apply(Joint.test.NoNa, 2, max, na.rm = TRUE) 
covars_Joint_min.test <- apply(Joint.test.NoNa, 2, min, na.rm = TRUE)
Joint_test_scaled <- as.data.frame(scale(Joint.test.NoNa, 
                        center = covars_Joint_min.test, 
                        scale = covars_Joint_max.test-covars_Joint_min.test))
covars_Joint_max.test_df<- data.frame(as.list(covars_Joint_max.test))
covars_Joint_min.test_df<- data.frame(as.list(covars_Joint_min.test))

n <- names(Joint_test_scaled)

```

<br> 

## Run Full Models 

Run full NNs Acoustic only, Visual only, and joint Acoustic/Visual datasets.

Models have the following characteristics: 
* 20 averaged repeats with random initalization. 
* Include 8 covariates 
* One hidden layer 
* Weighted training data 
* Tested 5, 10 and 20 node hidden layers. 
 
<br>

#### Model 1

```{r, echo = FALSE}
model1.indices <- c(1:5,7,8,10)
nMax1 <- length(model1.indices)
```
Try 5 node hidden layer.

```{r Ac. only Model 1, results = 'hide', message = FALSE, eval = FALSE, echo = FALSE}

# put together the formula
f.AcOnly_NN1 <- as.formula(paste("yAcOnly ~", paste(n[model1.indices], collapse = " + ")))
# train network
nn_AcOnly$v01 <- avNNet(f.AcOnly_NN1, data = AcOnly_train_scaled, 
                        size = 5, 
                        repeats = 20,
                        na.action = na.omit,
                        rang = 0.7, 
                        decay = 0.0001, 
                        maxit = 1000, 
                        trace=FALSE, entropy=TRUE)

# predict on train data and estimate Mean Squared Error (MSE)
pr.nn_AcOnly.v01_train <- predict(nn_AcOnly$v01,AcOnly_train_scaled[,model1.indices])
pr.nn_AcOnly.v01_train_unscale <- pr.nn_AcOnly.v01_train*(covars_AcOnly_max.train_df$yAcOnly
                                    - covars_AcOnly_min.train_df$yAcOnly)+covars_AcOnly_min.train_df$yAcOnly
MSE.nn_AcOnly$v01_train <- sum((AcOnly.train.NoNa$yAcOnly - 
                   pr.nn_AcOnly.v01_train_unscale)^2)/nrow(AcOnly.train.NoNa[model1.indices])

MSE.nn_AcOnly$v01_train

# predict on test data and estimate MSE
pr.nn_AcOnly.v01_test <- predict(nn_AcOnly$v01,AcOnly_test_scaled[,model1.indices])
pr.nn_AcOnly.v01_test_unscale <- pr.nn_AcOnly.v01_test*(covars_AcOnly_max.test_df$yAcOnly
                                    -covars_AcOnly_min.test_df$yAcOnly)+covars_AcOnly_min.test_df$yAcOnly

MSE.nn_AcOnly$v01_test <- sum((AcOnly.test.NoNa$yAcOnly - 
                   pr.nn_AcOnly.v01_test_unscale)^2)/nrow(AcOnly.test.NoNa[model1.indices])
MSE.nn_AcOnly$v01_test

```



```{r other models 1, eval = FALSE, echo = FALSE} 
## VISUAL ONLY
# put together the formula
f.VisOnly_NN1 <- as.formula(paste("yVisOnly ~", paste(n[model1.indices], collapse = " + ")))
# train network
nn_VisOnly$v01 <- avNNet(f.VisOnly_NN1, 
                         data = VisOnly_train_scaled, 
                         size = 5, 
                         repeats = 20,
                         na.action = na.omit,
                         rang = 0.7,  
                         decay = 0.0001, 
                         maxit = 10000, 
                         weights = VisOnly_train_scaled$weightsG0, trace=FALSE, entropy=TRUE)

# predict on train data and estimate MSE
pr.nn_VisOnly.v01_train <- predict(nn_VisOnly$v01,VisOnly_train_scaled[,model1.indices])
MSE.nn_VisOnly$v01_train <- sum((VisOnly_train_scaled$yVisOnly - 
                   pr.nn_VisOnly.v01_train)^2)/nrow(VisOnly_train_scaled[model1.indices])
MSE.nn_VisOnly$v01_train

# predict on test data and estimate MSE
pr.nn_VisOnly.v01_test <- predict(nn_VisOnly$v01,VisOnly_test_scaled[,model1.indices])
MSE.nn_VisOnly$v01_test <- sum((VisOnly_test_scaled$yVisOnly - 
                   pr.nn_VisOnly.v01_test)^2)/nrow(VisOnly_test_scaled[model1.indices])
MSE.nn_VisOnly$v01_test

## JOINT
f.Joint_NN1 <- as.formula(paste("y ~", paste(n[model1.indices], collapse = " + ")))
nn_Joint$v01 <- avNNet(f.Joint_NN1, data=Joint_train_scaled, 
                       size = 5, 
                       repeats = 20, 
                       na.action = na.omit,
                       rang = 0.7,  
                       decay = 0.0001, 
                       maxit = 10000, 
                       weights = Joint_train_scaled$weightsG0, trace=FALSE, entropy=TRUE)

pr.nn_Joint.v01_train <- predict(nn_Joint$v01,Joint_train_scaled[,model1.indices],na.action=na.omit)
MSE.nn_Joint$v01_train <- sum((Joint_train_scaled$y - 
               pr.nn_Joint.v01_train)^2)/nrow(Joint_train_scaled[model1.indices])
MSE.nn_Joint$v01_train

pr.nn_Joint.v01_test <- predict(nn_Joint$v01,Joint_test_scaled[,model1.indices],na.action=na.omit)
MSE.nn_Joint$v01_test <- sum((Joint_test_scaled$y - 
               pr.nn_Joint.v01_test)^2)/nrow(Joint_test_scaled[model1.indices])
MSE.nn_Joint$v01_test
```

<br>  

#### Model 2

Try 10 node hidden layer.
```{r Ac. Only Model 2, results = 'hide', message = FALSE, eval = FALSE, echo = FALSE}
# model2.indices <- c(1:5,7,11)
# nMax2 <- length(model2.indices)

# f.AcOnly_NN2 <- as.formula(paste("yAcOnly ~", paste(n[model2.indices], collapse = " + ")))
nn_AcOnly$v02 <- avNNet(f.AcOnly_NN1, 
                        data = AcOnly_train_scaled, 
                        size = 10,
                        repeats = 20,
                        na.action = na.omit,
                        rang = 0.7, 
                        decay = 0.0001, 
                        maxit = 1000, trace=FALSE,entropy=TRUE)

# predict on train data and estimate MSE
pr.nn_AcOnly.v02_train <- predict(nn_AcOnly$v02,AcOnly_train_scaled[,model1.indices])
pr.nn_AcOnly.v02_train_unscale <- pr.nn_AcOnly.v02_train*(covars_AcOnly_max.train_df$yAcOnly
                                    -covars_AcOnly_min.train_df$yAcOnly)+covars_AcOnly_min.train_df$yAcOnly
MSE.nn_AcOnly$v02_train <- sum((AcOnly.train.NoNa$yAcOnly - 
                   pr.nn_AcOnly.v02_train_unscale)^2)/nrow(AcOnly.train.NoNa[model1.indices])
MSE.nn_AcOnly$v02_train

# predict on test data and estimate MSE
pr.nn_AcOnly.v02_test <- predict(nn_AcOnly$v02,AcOnly_test_scaled[,model1.indices])
pr.nn_AcOnly.v02_test_unscale <- pr.nn_AcOnly.v02_test*(covars_AcOnly_max.test_df$yAcOnly
                                    -covars_AcOnly_min.test_df$yAcOnly)+covars_AcOnly_min.test_df$yAcOnly
MSE.nn_AcOnly$v02_test <- sum((AcOnly.test.NoNa$yAcOnly - 
                   pr.nn_AcOnly.v02_test_unscale)^2)/nrow(AcOnly.test.NoNa[model1.indices])
MSE.nn_AcOnly$v02_test
```



```{r other models 2, eval = FALSE, echo = FALSE} 
## VISUAL ONLY
# f.VisOnly_NN2 <- as.formula(paste("yVisOnly ~", paste(n[model2.indices], collapse = " + ")))
nn_VisOnly$v02 <- avNNet(f.VisOnly_NN1, 
                         data=VisOnly_train_scaled, 
                         size = 10, 
                         repeats = 20,
                         na.action = na.omit,
                         rang = 0.7,  
                         decay = 0.0001, 
                         maxit = 10000, 
                         weights = VisOnly_train_scaled$weightsG0, 
                         trace=FALSE, entropy = TRUE)


# predict on train data and estimate MSE
pr.nn_VisOnly.v02_train <- predict(nn_VisOnly$v02,VisOnly_train_scaled[,model1.indices])
MSE.nn_VisOnly$v02_train <- sum((VisOnly_train_scaled$yVisOnly - 
                   pr.nn_VisOnly.v02_train)^2)/nrow(VisOnly_train_scaled[model1.indices])
MSE.nn_VisOnly$v02_train

# predict on test data and estimate MSE
pr.nn_VisOnly.v02_test <- predict(nn_VisOnly$v02,VisOnly_test_scaled[,model1.indices])
MSE.nn_VisOnly$v02_test <- sum((VisOnly_test_scaled$yVisOnly - 
                   pr.nn_VisOnly.v02_test)^2)/nrow(VisOnly_test_scaled[model1.indices])
MSE.nn_VisOnly$v02_test

## JOINT
# f.Joint_NN2 <- as.formula(paste("y ~", paste(n[model2.indices], collapse = " + ")))
nn_Joint$v02 <- avNNet(f.Joint_NN1, 
                       data = Joint_train_scaled, 
                       size = 10, 
                       repeats = 20,
                       na.action = na.omit,
                       rang = 0.7,  
                       decay = 0.0001, 
                       maxit = 10000,
                       weights = Joint_train_scaled$weightsG0, 
                       trace = FALSE, entropy = TRUE)
# Predict and evaluate MSE on training data
pr.nn_Joint.v02_train <- predict(nn_Joint$v02,Joint_train_scaled[,model1.indices],na.action=na.omit)
MSE.nn_Joint$v02_train <- sum((Joint_train_scaled$y - 
               pr.nn_Joint.v02_train)^2)/nrow(Joint_train_scaled[model1.indices])
MSE.nn_Joint$v02_train

pr.nn_Joint.v02_test <- predict(nn_Joint$v02,Joint_test_scaled[,model1.indices],na.action=na.omit)
MSE.nn_Joint$v02_test <- sum((Joint_test_scaled$y - 
               pr.nn_Joint.v02_test)^2)/nrow(Joint_test_scaled[model1.indices])
MSE.nn_Joint$v02_test
```


<br> 

#### Model 3

Try 20 node hidden layer.
```{r Ac Only Model 3, results = 'hide', message = FALSE, eval = FALSE, echo = FALSE}
# model3.indices <- c(1:5,7,12)
# nMax3 <- length(model3.indices)

# f.AcOnly_NN3 <- as.formula(paste("yAcOnly ~", paste(n[model3.indices], collapse = " + ")))
nn_AcOnly$v03 <- avNNet(f.AcOnly_NN1, 
                        data = AcOnly_train_scaled, 
                        size = 20, 
                        repeats = 20,
                        na.action = na.omit,
                        rang = 0.7, 
                        decay = 0.0001, 
                        maxit = 1000, 
                        trace = FALSE, entropy = TRUE)

# predict on train data and estimate MSE
pr.nn_AcOnly.v03_train <- predict(nn_AcOnly$v03,AcOnly_train_scaled[,model1.indices])
pr.nn_AcOnly.v03_train_unscale <- pr.nn_AcOnly.v03_train*(covars_AcOnly_max.train_df$yAcOnly
                                    -covars_AcOnly_min.train_df$yAcOnly)+covars_AcOnly_min.train_df$yAcOnly
MSE.nn_AcOnly$v03_train <- sum((AcOnly.train.NoNa$yAcOnly - 
                   pr.nn_AcOnly.v03_train_unscale)^2)/nrow(AcOnly.train.NoNa[model1.indices])
MSE.nn_AcOnly$v03_train

# predict on test data and estimate MSE
pr.nn_AcOnly.v03_test <- predict(nn_AcOnly$v03,AcOnly_test_scaled[,model1.indices])
pr.nn_AcOnly.v03_test_unscale <- pr.nn_AcOnly.v03_test*(covars_AcOnly_max.test_df$yAcOnly
                                    -covars_AcOnly_min.test_df$yAcOnly)+covars_AcOnly_min.test_df$yAcOnly
MSE.nn_AcOnly$v03_test <- sum((AcOnly.test.NoNa$yAcOnly - 
                   pr.nn_AcOnly.v03_test_unscale)^2)/nrow(AcOnly.test.NoNa[model1.indices])
MSE.nn_AcOnly$v03_test
```



```{r other models 3, eval = FALSE, echo = FALSE} 
## Vis Only
#f.VisOnly_NN3 <- as.formula(paste("yVisOnly ~", paste(n[model3.indices], collapse = " + ")))
nn_VisOnly$v03 <- avNNet(f.VisOnly_NN1, 
                         data = VisOnly_train_scaled, 
                         size = 20, 
                         repeats = 20,
                         na.action = na.omit,
                         rang = 0.7,
                         decay = 0.0001, 
                         maxit = 10000, 
                         weights = VisOnly_train_scaled$weightsG0, 
                         trace = FALSE, entropy = TRUE)
# predict on train data and estimate MSE
pr.nn_VisOnly.v03_train <- predict(nn_VisOnly$v03,VisOnly_train_scaled[,model1.indices])
MSE.nn_VisOnly$v03_train <- sum((VisOnly_train_scaled$yVisOnly - 
                   pr.nn_VisOnly.v03_train)^2)/nrow(VisOnly_train_scaled[model1.indices])
MSE.nn_VisOnly$v03_train

# predict on test data and estimate MSE
pr.nn_VisOnly.v03_test <- predict(nn_VisOnly$v03,VisOnly_test_scaled[,model1.indices])
MSE.nn_VisOnly$v03_test <- sum((VisOnly_test_scaled$yVisOnly - 
                   pr.nn_VisOnly.v03_test)^2)/nrow(VisOnly_test_scaled[model1.indices])
MSE.nn_VisOnly$v03_test


## JOINT
#f.Joint_NN3 <- as.formula(paste("y ~", paste(n[model3.indices], collapse = " + ")))
nn_Joint$v03 <- avNNet(f.Joint_NN1, 
                       data = Joint_train_scaled, 
                       size = 20, 
                       repeats = 20,
                       na.action = na.omit,
                       rang = 0.7,  
                       decay = 0.0001, 
                       maxit = 10000, 
                       weights = Joint_train_scaled$weightsG0, 
                       trace=FALSE, entropy=TRUE)

# Predict and evaluate MSE on training data
pr.nn_Joint.v03_train <- predict(nn_Joint$v03,Joint_train_scaled[,model1.indices],na.action=na.omit)
MSE.nn_Joint$v03_train <- sum((Joint_train_scaled$y - 
               pr.nn_Joint.v03_train)^2)/nrow(Joint_train_scaled[model1.indices])
MSE.nn_Joint$v03_train

pr.nn_Joint.v03_test <- predict(nn_Joint$v03,Joint_test_scaled[,model1.indices],na.action=na.omit)
MSE.nn_Joint$v03_test <- sum((Joint_test_scaled$y - 
               pr.nn_Joint.v03_test)^2)/nrow(Joint_test_scaled[model1.indices])
MSE.nn_Joint$v03_test
```


```{r save models, eval = FALSE, echo = FALSE}
# Save models if re-calculating everything
save(nn_AcOnly,MSE.nn_AcOnly,file = paste(outDir,SP,'_AcOnly_NN.Rdata',sep=''))
save(nn_VisOnly,MSE.nn_VisOnly,file = paste(outDir,SP,'_VisOnly_NN.Rdata',sep=''))
save(nn_Joint,MSE.nn_Joint,file = paste(outDir,SP,'_Joint_NN.Rdata',sep=''))
```

```{r load models, eval = TRUE, echo = FALSE}
# alternative if models are already calculated
load(paste(outDir,SP,'_AcOnly_NN.Rdata',sep=''))
load(paste(outDir,SP,'_VisOnly_NN.Rdata',sep=''))
load(paste(outDir,SP,'_Joint_NN.Rdata',sep=''))
```

<br>

# III. Model Comparisons

All models perform about equally. More networks with more nodes in the hidden layer fit training data better, but seems like overfitting might be happening because performance on test data gets worse.

Compare acoustic only models:
```{r}
print(MSE.nn_AcOnly, digits = 2)
```

<br> 


Compare visual-only models:
```{r}
print(MSE.nn_VisOnly, digits = 2)
```

<br> 

Compare joint models:
```{r}
print(MSE.nn_Joint, digits = 2)
```

<br> 

Model 1 seems to do as well as the more complex ones, so go with the simple (5 node) option.

<br> 

<br> 



# IV. Predict on Test Data

## Temporal prediction

Predict on acoustic test data, and compare with actual observations for 2013. We are comparing the predicted probability of encountering animals with the actual weekly rate of occurrence of animals at a site. 

CAVEAT: Encounter probability from the data is estimated as fraction of days per week during which this species was detected. This results in a pretty coarse estimate.
Alternatively we could compare to daily densities or something, but then the y-axis scales are completely different and it may be an apples to oranges comparison. An earlier version used densities, and seemed to suggest that lagging variables might be appropriate.


<br>

#### Acoustic Only Prediction
```{r Ac Temporal Predict, echo = FALSE, warning = FALSE}
# Predict on acoustic test data, using acoustic only model for comparison...
compAcSet_MC <- which((Test_AcOnly.set$fac2)==5)
compAcSet_GC <- which((Test_AcOnly.set$fac2)==10)
compAcSet_DT <- which((Test_AcOnly.set$fac2)==15 |
                        (Test_AcOnly.set$fac2)==16)
compAcSet_DC <- which((Test_AcOnly.set$fac2)==21 |
                        (Test_AcOnly.set$fac2)==22)
compAcSet_MP <- which((Test_AcOnly.set$fac2)==26)

# Predict in time
dateTicks = as.POSIXct(c('2013-01-01 GMT','2013-04-01 GMT',
                         '2013-07-01 GMT','2013-10-01 GMT',
                         '2014-01-01 GMT'))
dateLabels = c('Jan. 2013','Apr. 2013','Jul. 2013','Oct 2013','Jan. 2014')

predAcOnly_MC <- predict(nn_AcOnly$v01,AcOnly_test_scaled[compAcSet_MC,model1.indices])
predAcOnly_GC <- predict(nn_AcOnly$v01,AcOnly_test_scaled[compAcSet_GC,model1.indices])
predAcOnly_DT <- predict(nn_AcOnly$v01,AcOnly_test_scaled[compAcSet_DT,model1.indices])
predAcOnly_DC <- predict(nn_AcOnly$v01,AcOnly_test_scaled[compAcSet_DC,model1.indices])
predAcOnly_MP <- predict(nn_AcOnly$v01,AcOnly_test_scaled[compAcSet_MP,model1.indices])

occurIdx = which(as.POSIXct(pOccur[,1])>='2013-01-01' & as.POSIXct(pOccur[,1])<'2014-01-01')


AcOnly_predictionSet <- data.frame(unique(Test_AcOnly.set$date))
colnames(AcOnly_predictionSet) <-"date"
AcOnly_predictionSet$MC <- NA
MC_times <- Test_AcOnly.set$date[compAcSet_MC]
m1 <- match(MC_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$MC[m1] <-predAcOnly_MC

AcOnly_predictionSet$GC <- NA
GC_times <- Test_AcOnly.set$date[compAcSet_GC]
m2 <- match(GC_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$GC[m2] <-predAcOnly_GC

AcOnly_predictionSet$DT <- NA
DT_times <- Test_AcOnly.set$date[compAcSet_DT]
m3 <- match(DT_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$DT[m3] <-predAcOnly_DT

AcOnly_predictionSet$DC <- NA
DC_times <- Test_AcOnly.set$date[compAcSet_DC]
m4 <- match(DC_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$DC[m4] <-predAcOnly_DC

AcOnly_predictionSet$MP <- NA
MP_times <- Test_AcOnly.set$date[compAcSet_MP]
m5 <- match(MP_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$MP[m5] <-predAcOnly_MP


AcOnly_predictionSet$Legend <- "Predictions"

pOccur$Legend <- "Observations"
```


```{r,fig.height = 10, fig.width = 7, message = FALSE, warning = FALSE, echo = FALSE}
# par(mfrow = c(5,1),oma=c(3,0,5,0)),colour="#000099",colour="#CC0000"
p1_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MC, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=MC, color = Legend)) +
  labs(y = "", x = "")+
  scale_color_manual("",values= c("gray48","#009999"))+
  theme(legend.position = c(0.9, 0.7))

p2_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = GC, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=GC, color = Legend))+
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p3_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DT, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")

p4_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DC, color = Legend))+  
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=DC, color = Legend)) +
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p5_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = MP, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=MP, color = Legend))+
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "", x = "Date")+
  theme(legend.position="none")


multiplot(p1_Ac, p2_Ac, p3_Ac, p4_Ac, p5_Ac, cols=1)

```
<br>

#### Visual Only Prediction

```{r Vis Temporal Predict, warning = FALSE, echo = FALSE}
# Confusing, but acoustic only predictors are passed in to since
# we're predicting on the acoustic timeseries.
predVisOnly_MC <- predict(nn_VisOnly$v01,AcOnly_test_scaled[compAcSet_MC,model1.indices])
predVisOnly_GC <- predict(nn_VisOnly$v01,AcOnly_test_scaled[compAcSet_GC,model1.indices])
predVisOnly_DT <- predict(nn_VisOnly$v01,AcOnly_test_scaled[compAcSet_DT,model1.indices])
predVisOnly_DC <- predict(nn_VisOnly$v01,AcOnly_test_scaled[compAcSet_DC,model1.indices])
predVisOnly_MP <- predict(nn_VisOnly$v01,AcOnly_test_scaled[compAcSet_MP,model1.indices])

VisOnly_predictionSet <- data.frame(unique(Test_AcOnly.set$date))
colnames(VisOnly_predictionSet) <-"date"
VisOnly_predictionSet$MC <- NA
m1 <- match(MC_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$MC[m1] <-predVisOnly_MC

VisOnly_predictionSet$GC <- NA
m2 <- match(GC_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$GC[m2] <-predVisOnly_GC

VisOnly_predictionSet$DT <- NA
m3 <- match(DT_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$DT[m3] <-predVisOnly_DT

VisOnly_predictionSet$DC <- NA
m4 <- match(DC_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$DC[m4] <-predVisOnly_DC

VisOnly_predictionSet$MP <- NA
m5 <- match(MP_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$MP[m5] <-predVisOnly_MP


VisOnly_predictionSet$Legend <- "Predictions"
```

```{r,fig.height = 10, fig.width = 7, message = FALSE, warning = FALSE, echo = FALSE}
# par(mfrow = c(5,1),oma=c(3,0,5,0)),colour="#000099",colour="#CC0000"
p1_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MC, color = Legend))+
  geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=MC, color = Legend)) +
  labs(y = "", x = "")+
  scale_color_manual(values= c("gray48","#009999"))+
  theme(legend.position = c(0.9, 0.7))

p2_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = GC, color = Legend))+
  geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=GC, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p3_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DT, color = Legend))+
    geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")

p4_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DC, color = Legend))+
  geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=GC, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p5_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = MP, color = Legend))+
    geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")

multiplot(p1_Vis, p2_Vis, p3_Vis, p4_Vis, p5_Vis, cols=1)

```

<br>

#### Joint Prediction

```{r Combo Temporal Predict,fig.height = 10, fig.width = 7, warning = FALSE, echo = FALSE}
# Confusing, but acoustic only predictors are passed in to since we're predicting on the acoustic timeseries.
pred_MC <- predict(nn_Joint$v01,AcOnly_test_scaled[compAcSet_MC,model1.indices])
pred_GC <- predict(nn_Joint$v01,AcOnly_test_scaled[compAcSet_GC,model1.indices])
pred_DT <- predict(nn_Joint$v01,AcOnly_test_scaled[compAcSet_DT,model1.indices])
pred_DC <- predict(nn_Joint$v01,AcOnly_test_scaled[compAcSet_DC,model1.indices])
pred_MP <- predict(nn_Joint$v01,AcOnly_test_scaled[compAcSet_MP,model1.indices])

Both_predictionSet <- data.frame(unique(Test_AcOnly.set$date))
colnames(Both_predictionSet) <-"date"
Both_predictionSet$MC <- NA
m1 <- match(MC_times,Both_predictionSet$date)
Both_predictionSet$MC[m1] <-pred_MC

Both_predictionSet$GC <- NA
m2 <- match(GC_times,Both_predictionSet$date)
Both_predictionSet$GC[m2] <-pred_GC

Both_predictionSet$DT <- NA
m3 <- match(DT_times,Both_predictionSet$date)
Both_predictionSet$DT[m3] <-pred_DT

Both_predictionSet$DC <- NA
m4 <- match(DC_times,Both_predictionSet$date)
Both_predictionSet$DC[m4] <-pred_DC

Both_predictionSet$MP <- NA
m5 <- match(MP_times,Both_predictionSet$date)
Both_predictionSet$MP[m5] <-pred_MP

Both_predictionSet$Legend <- "Predictions"
```

```{r,fig.height = 10, fig.width = 7, message = FALSE, warning = FALSE, echo = FALSE}
# par(mfrow = c(5,1),oma=c(3,0,5,0)),colour="#000099",colour="#CC0000"
p1 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MC, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x=date, y=MC, color = Legend)) +
  labs(y = "", x = "")+
  scale_color_manual(values= c("gray48","#009999"))+
  theme(legend.position = c(0.9, 0.7))

p2 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = GC, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x=date, y=GC, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p3 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DT, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")

p4 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = DC, color = Legend))+  
  geom_line(data = Both_predictionSet,
            aes(x = date, y = DC, color = Legend)) +
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position = "none")

p5 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MP, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x = date, y = MP, color = Legend))+
  scale_color_manual("",values = c("gray48","#009999"))+
  labs(y = "", x = "Date")+
  theme(legend.position = "none")

multiplot(p1, p2, p3, p4, p5, cols = 1)

```
<br>

## Spatial Prediction

```{r load raster bricks, echo = FALSE}
load('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/2009_prediction_rasters_scaled.Rdata') 
```


Evaluate the models for summer (July 2009) and winter(January 2009) across the entire Gulf of Mexico (US EEZ beyond the 200m contour).
```{r Ac Spatial Predict, warning = FALSE, echo = FALSE}
### Acoustic Only spatial prediction

dt1 <- as.data.frame(jan2009_rasters,xy=TRUE)

jan2009_AcOnly_prediction <- raster::predict(jan2009_rasters,nn_AcOnly$v01,
                                             na.action = na.pass)
            
july2009_AcOnly_prediction <- raster::predict(july2009_rasters,nn_AcOnly$v01,na.action = na.pass)    
```


```{r Vis Spatial Predict, warning = FALSE, echo = FALSE}
### Visual Only spatial prediction
dt1 <- as.data.frame(jan2009_rasters,xy=TRUE)

jan2009_VisOnly_prediction <- raster::predict(jan2009_rasters,nn_VisOnly$v01,na.action = na.pass)
            
july2009_VisOnly_prediction <- raster::predict(july2009_rasters,nn_VisOnly$v01,
            na.action = na.pass)    
```


```{r Combo Spatial Predict, warning = FALSE, echo=FALSE}
### Joint Visual and Acoustic spatial prediction

dt1 <- as.data.frame(jan2009_rasters,xy=TRUE)

jan2009_prediction <- raster::predict(jan2009_rasters,nn_Joint$v01,na.action = na.pass)
            
july2009_prediction <- raster::predict(july2009_rasters,nn_Joint$v01,na.action = na.pass)    
```



```{r wrangle projections, message = FALSE, warning = FALSE, echo = FALSE, results = 'hide'}
# Wrangle projections for mapping:

predict_template <- readOGR('E:/NASData/AcoustoVisualDE/Prediction_template/prediction_polygon.shp')
map_proj <- sp::CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')
predict_template_proj <- spTransform(predict_template, CRSobj = map_proj)

# Acoustic
jan2009_AcOnly_prediction_proj <- projectRaster(jan2009_AcOnly_prediction, crs=map_proj)
july2009_AcOnly_prediction_proj <- projectRaster(july2009_AcOnly_prediction, crs=map_proj)
jan2009_AcOnly_prediction_crop <- mask(jan2009_AcOnly_prediction_proj,predict_template_proj)
july2009_AcOnly_prediction_crop <-
  mask(july2009_AcOnly_prediction_proj,predict_template_proj)

# Visual
jan2009_VisOnly_prediction_proj <- 
  projectRaster(jan2009_VisOnly_prediction, crs=map_proj)
july2009_VisOnly_prediction_proj <- 
  projectRaster(july2009_VisOnly_prediction, crs=map_proj)
#jan2009_VisOnly_prediction_SE_proj <- 
#  projectRaster(jan2009_VisOnly_prediction_SE, crs=map_proj)

jan2009_VisOnly_prediction_crop <- 
  mask(jan2009_VisOnly_prediction_proj,predict_template_proj)
july2009_VisOnly_prediction_crop <- mask(july2009_VisOnly_prediction_proj,predict_template_proj)
#jan2009_VisOnly_prediction_SE_crop <- mask(jan2009_VisOnly_prediction_SE_proj,predict_template_proj)

#Both
jan2009_prediction_proj <- projectRaster(jan2009_prediction, crs=map_proj)
july2009_prediction_proj <- projectRaster(july2009_prediction, crs=map_proj)
jan2009_prediction_crop <- mask(jan2009_prediction_proj,predict_template_proj)
july2009_prediction_crop <- mask(july2009_prediction_proj,predict_template_proj)
```
<br>

```{r Model Averaging, warning = FALSE, echo=FALSE}
### Model averaging 

# Alternatively, the visual and acoustic models could be averaged.

jan2009mean <- mean(jan2009_AcOnly_prediction_crop,jan2009_VisOnly_prediction_crop)
july2009mean <- mean(july2009_AcOnly_prediction_crop,july2009_VisOnly_prediction_crop)

```


Summer 2009 predicted distribution and test sightings:


```{r leaflet summer, message = FALSE, warning = FALSE, echo=FALSE}
# Display summer (July 2009) map:
pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,1), 
                    na.color = 'transparent')
GU2009Effort = shapefile('E:/NASData/GU2009Effort/GU_Effort_Merge_clip.shp')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(july2009_AcOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Acoustic July 2009') %>%
  addRasterImage(july2009_VisOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Visual July 2009') %>%
  addRasterImage(july2009_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Joint July 2009') %>%
  addRasterImage(july2009mean,colors = pal,
                 opacity = 0.8, group = 'Vis. & Ac. Mean July 2009') %>% 
  addPolylines(data=GU2009Effort,group ='Visual Effort (Summer 2009)', opacity = 1,
               color = "black", weight = 2)%>%
  addCircleMarkers(data = sightingsTest, lng = ~ long, lat = ~ lat,color = "black",
                 stroke = TRUE, fillOpacity = 0.8,radius = 6,
                 group = 'Test Sightings (Summer 2009)') %>%
  addLegend(pal = pal, values = c(0,1),
    title = 'P(encounter)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Acoustic July 2009','Visual July 2009',
                   'Joint July 2009','Vis. & Ac. Mean July 2009'),
    overlayGroups = c('Test Sightings (Summer 2009)', 'Visual Effort (Summer 2009)'),
    options = layersControlOptions(collapsed = FALSE)
  )
map

```

<br>
Winter 2009 predicted distribution:

```{r leaflet winter, message = FALSE, warning = FALSE, echo=FALSE}
# Display winter (January 2009) map:
pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,1), 
                    na.color = 'transparent')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(jan2009_AcOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Acoustic Jan. 2009') %>%
  addRasterImage(jan2009_VisOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Visual Jan. 2009') %>%
  addRasterImage(jan2009_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Joint Jan. 2009') %>%
  addRasterImage(jan2009mean,colors = pal,
                 opacity = 0.8, group = 'Vis. & Ac. Mean Jan. 2009') %>%
  addLegend(pal = pal, values = c(0,1),
    title = 'P(encounter)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Acoustic Jan. 2009','Visual Jan. 2009',
                   'Joint Jan. 2009','Vis. & Ac. Mean Jan. 2009'),
    options = layersControlOptions(collapsed = FALSE)
  )
map

```


<br>

# V. Monthly model predictions

Spatial model predictions using oceanographic variables averaged by month between 2003 and 2015.

```{r evaluate climatology-based models, echo=FALSE, message = FALSE, warning = FALSE}
load('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/climatology_rasters_scaled.Rdata') 
monthNum <-c('01','02','03','04','05','06','07','08','09','10','11','12')
monthStr<-c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')

climatePrediction <- vector('list',length = 12)
mapClimatePrediction <- vector('list',length = 12)

for (iM in 1:length(monthStr)){
  climatePrediction[[iM]] <- raster::predict(raster_set[[iM]],nn_Joint$v01,
           na.action = na.pass)
  mapClimatePrediction[[iM]] <- mask(projectRaster(climatePrediction[[iM]], crs=map_proj),predict_template_proj)  
  # output raster to geotiff
  rasterImageFileName = paste0(savePath,'/climatology_predictions/', SP,'_',monthStr[iM],'NN_mean_encounter_probability.tif')
  writeRaster(mapClimatePrediction[[iM]],filename = rasterImageFileName, format="GTiff",overwrite = TRUE)
  
  #ouput raster to kml
  kmlImageFileName = paste0(savePath,'/climatology_predictions/', SP,'_',monthStr[iM],'NN_mean_encounter_probability.kml')
  KML(mapClimatePrediction[[iM]],file = kmlImageFileName, col=matlab.like2(32),overwrite = TRUE)
  

}
  
```

```{r plot climatologies, message = FALSE, warning = FALSE, echo=FALSE}
pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,1), 
                    na.color = 'transparent')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(mapClimatePrediction[[1]] , colors = pal,
                 opacity = 0.8, group = 'Jan.') %>%
  addRasterImage(mapClimatePrediction[[3]] , colors = pal,
                 opacity = 0.8, group = 'March') %>%
  addRasterImage(mapClimatePrediction[[5]] , colors = pal,
                 opacity = 0.8, group = 'May') %>%
  addRasterImage(mapClimatePrediction[[7]] , colors = pal,
                 opacity = 0.8, group = 'July') %>%
  addRasterImage(mapClimatePrediction[[9]] ,colors = pal,
                 opacity = 0.8, group = 'Sept.') %>%
  addRasterImage(mapClimatePrediction[[11]] ,colors = pal,
                 opacity = 0.8, group = 'Nov.') %>%
  addMarkers(data = HARPsites, lng = ~ long, lat = ~ lat) %>%
  addLegend(pal = pal, values = c(0,1),
    title = 'P(encounter)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Jan.','March','May',
                   'July','Sept.','Nov.'),
    options = layersControlOptions(collapsed = FALSE)
  )
map
```