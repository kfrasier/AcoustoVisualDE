---
title: 'GoMx _Kogia_ spp. habitat models'
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    theme: spacelab
    fig_caption: true 

---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages, echo = FALSE, message = FALSE, warning = FALSE}
library(rgdal)
library(raster)
library(ggplot2)
library(rgeos)
library(mapview)
library(leaflet)
library(psych)
library(broom)
library(plotrix)
library(magrittr)
library(colorRamps)
library(lubridate)
library(HabitatProject)
library(nnet)
library(caret)
library(parallel)
library(MLmetrics)
library(pracma)
library(knitr)
source('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/nnet_plot_update.r')
source('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/HabitatProject/R/weighted_logloss.R')
source('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/HabitatProject/R/multiplot.R')
source('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/nnet_plot_update.r')
options(stringsAsFactors = FALSE)
# load some preferences
load('E:/NASData/ModelData/Kspp/setup_info_Kspp.Rdata')
load('E:/NASData/ModelData/Kspp/KsppMergedData.Rdata')
outDir <- file.path('E:/NASData/ModelData',SP,'/')
```
<br>

# 1. Exploratory analysis

<br>

## 1.1 Data Inputs

NOAA SEFSC visual data goes back to 1992, but as shown in the figure below, many predictor variables are only available starting in 2003, therefore earlier visual data is currently excluded from further analyses. 

Note: Future work could use monthly climatologies (averages) so that older sightings data could be used. Some dynamic drivers like eddy and front locations would not be able to be considered using that approach.

```{r Missing data, echo = FALSE}
covarList<-names(mergedSegments[c(2,5:length(mergedSegments))])

percFilled <- plot.missingdata(mergedSegments,covarList,paste0(outDir,'AcousticAndVisual_',SP)) 
percFilled <- plot.missingdata(AcOnlySegments,covarList,paste0(outDir,'AcousticOnly_',SP)) 
percFilled <- plot.missingdata(VisOnlySegments,covarList,paste0(outDir,'VisualOnly_',SP)) 
```

**Visual data predictor variable availability:** 

![](E:/NASData/ModelData/Kspp/VisualOnly_Kspp_missingData.png)

<br> 

<br> 

### 1.1.1 Testing and Training Sets

The data are split into training and testing sets. In this case, data from 2009 and 2013 are used for testing. Only observations post-2003 are used for modeling due to covariate limitations.

```{r test train split, echo = FALSE}
# If you decide from the missing data plots that you want to restrict years going forward:
yearListIdx = as.numeric(format(mergedSegments$date,"%Y"))
yearListIdx_AcOnly = as.numeric(format(AcOnlySegments$date,"%Y"))
yearListIdx_VisOnly = as.numeric(format(VisOnlySegments$date,"%Y"))

keepDates.train <- which(yearListIdx != 2009 & yearListIdx >= 2003 & yearListIdx <= 2012)
keepDates.test <- which(yearListIdx == 2009 | yearListIdx == 2013)
keepDates_AcOnly.train <- which(yearListIdx_AcOnly != 2009 & yearListIdx_AcOnly >= 2003 & yearListIdx_AcOnly <= 2012)
keepDates_AcOnly.test <- which(yearListIdx_AcOnly == 2009 | yearListIdx_AcOnly == 2013)
keepDatesVisOnly.train <- which(yearListIdx_VisOnly != 2009 & yearListIdx_VisOnly >= 2003)
keepDatesVisOnly.test <- which(yearListIdx_VisOnly == 2009)

mergedTrain.set<- mergedSegments[keepDates.train,]
Train_AcOnly.set <- AcOnlySegments[keepDates_AcOnly.train,]
Train_VisOnly.set<- VisOnlySegments[keepDatesVisOnly.train,]

mergedTest.set<- mergedSegments[keepDates.test,]
Test_AcOnly.set<- AcOnlySegments[keepDates_AcOnly.test,]
Test_VisOnly.set<- VisOnlySegments[keepDatesVisOnly.test,]
```


<br>

### 1.1.2 Preliminary Mapping

The visual data selected for modeling are displayed on the map below. Data from 2009 were held back for testing. Blue markers indicate HARP locations.

```{r map inputs, warning = FALSE, echo = FALSE}
#Get test visual sightings
sightingsTrain <- Train_VisOnly.set[Train_VisOnly.set$Density>0,c('lat','long','date')]

sightingsTest <- Test_VisOnly.set[Test_VisOnly.set$Density>0,c('lat','long','date')]
HARPsites <- unique(Train_AcOnly.set[c('lat','long')])
pal <-colorFactor(palette = "RdYlGn", 
                  domain = c(2003,2004,2009,2012,2014))
  
map1 <- leaflet() %>%  setView(lng = -89.4, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addCircleMarkers(data = sightingsTrain, lng = ~ long, lat = ~ lat,color = ~pal(year(date)),
                 stroke = TRUE, fillOpacity = 0.8, group = 'Training Set',radius = 4)%>%
  addCircleMarkers(data = sightingsTest, lng = ~ long, lat = ~ lat,color = ~pal(year(date)),
                 stroke = TRUE, fillOpacity = 0.8, group = 'Test Set',radius = 4)%>%
  addMarkers(data = HARPsites, lng = ~ long, lat = ~ lat) %>%
  addLegend(pal = pal,values = c(2003,2004,2009,2012,2014),title = 'Year') 

map1
```
<br>

The time series below show the acoustic data used for modeling. Data from 2011 and 2012 used for training, and 2013 data is held back for testing. These density magnitudes are very preliminary,and models only used presence absence data.

<br> 

**Acoustic Timeseries:**
```{r plot timeseries, message = FALSE, echo = FALSE}
plot.timeseries(siteList,outDir,AcOnlySegments)
```



![](E:/NASData/ModelData/Kspp/Kspp_Timeseries_Site_MC.png)
![](E:/NASData/ModelData/Kspp/Kspp_Timeseries_Site_GC.png)
![](E:/NASData/ModelData/Kspp/Kspp_Timeseries_Site_DT.png)

<br> 

## 1.2 Examine Covariates

```{r remove outliers, message = FALSE, results = 'hide', echo = FALSE}
# Replace extreme outliers (bad data) with NaNs.
outlierList <-which(mergedSegments$CHL< -10)
mergedSegments$CHL[outlierList] <- NaN 
outlierList <-which(mergedSegments$FrontDist_Cayula>800000)
mergedSegments$FrontDist_Cayula[outlierList] <- NaN 
outlierList <-which(mergedSegments$Density>10000)
mergedSegments$Density[outlierList] <- NaN 

outlierList <-which(AcOnlySegments$CHL< -10)
AcOnlySegments$CHL[outlierList] <- NaN 
outlierList <-which(AcOnlySegments$FrontDist_Cayula>800000)
AcOnlySegments$FrontDist_Cayula[outlierList] <- NaN 
outlierList <-which(AcOnlySegments$Density>10000)
AcOnlySegments$Density[outlierList] <- NaN 

outlierList <-which(VisOnlySegments$CHL<  -10)
VisOnlySegments$CHL[outlierList] <- NaN 
outlierList <-which(VisOnlySegments$FrontDist_Cayula>800000)
VisOnlySegments$FrontDist_Cayula[outlierList] <- NaN 
outlierList <-which(VisOnlySegments$Density>10000)
VisOnlySegments$Density[outlierList] <- NaN 
```


### 1.2.1 Check Covariate Distributions

Covariates have different distributions across the observations. 
<br> 

**Distributions of covariates from acoustic observations:**

```{r dot plots, eval = TRUE, message = FALSE, results = 'hide', echo = FALSE}
plot.cleveland(mergedTrain.set,covarList,FALSE,paste0(outDir,'AcousticAndVisual_',SP))
plot.cleveland(Train_AcOnly.set,covarList,FALSE,paste0(outDir,'AcousticOnly_',SP))
plot.cleveland(Train_VisOnly.set,covarList,FALSE,paste0(outDir,'VisualOnly_',SP))
```

![](E:/NASData/ModelData/Kspp/AcousticOnly_Kspp_clevelandDots_noTransform.png)


<br>

**Distributions of covariates from the visual observations:**

![](E:/NASData/ModelData/Kspp/VisualOnly_Kspp_clevelandDots_noTransform.png)

<br>

Some of these covariates are more or less interrelated. HYCOM estimates of salinity at the surface (HYCOM_SALIN_0) and at 100m (HYCOM_SALIN_100) are very similar, so I selected surface salinity for simplicity. HYCOM current and upwelling estimates at 100m were also removed (HYCOM_MAG_100,HYCOM_UPVEL_100). HYCOM current direction is site specific in the acoustic data, so it was excluded for now. 


Remaining correlations are examined in the figure below. Numbers closer to 1 above the diagonal in the figure below represent correlation coefficients. Highly correlated covariates should not be used together in the same model. Day of year was excluded to avoid artifacts associated with the temporal differences of the datasets (Acoustic data are year-round, and visual data are collected in spring/summer).



```{r correlation plots, eval = TRUE, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE}
covarList2 <- c("SST","SSH","CHL","HYCOM_MLD",
                "HYCOM_SALIN_0","HYCOM_DIR_0",
                "HYCOM_MAG_0",
                "HYCOM_UPVEL_50","FrontDist_Cayula",
                "EddyDist","Neg_EddyDist","Pos_EddyDist",
                "DayOfYear","fac1","fac2")

# restrict covariates again to limited set
mergedTrain.set2<- mergedTrain.set[,covarList2]
mergedTest.set2<- mergedTest.set[,covarList2]
Train_AcOnly.set2<- Train_AcOnly.set[,covarList2]
Test_AcOnly.set2<- Test_AcOnly.set[,covarList2]
Train_VisOnly.set2<- Train_VisOnly.set[,covarList2]
Test_VisOnly.set2<- Test_VisOnly.set[,covarList2]

# without transform
png(paste(outDir,SP,'_correlations_noTransform.png',sep=''), width = 2000, height = 1600)
pairs.panels(mergedTrain.set2[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off()
png(paste(outDir,SP,'_correlations_noTransform_AcOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(Train_AcOnly.set2[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off()
png(paste(outDir,SP,'_correlations_noTransform_visOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(Train_VisOnly.set2[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off()

```
<br> 

**Covariate Correlations:**

![](E:/NASData/ModelData/Kspp/Kspp_correlations_noTransform.png)

<br>

### 1.2.2 Transform Predictor Variables

Some variables, including chlorophyll, current magnitude, mixed layer depth and distance to fronts are highly skewed and were log-transformed.

```{r transform covars, message = FALSE, results = 'hide', echo = FALSE, warning = FALSE}
# covarList2 <- c("SST","SSH","CHL","HYCOM_MLD",
#                 "HYCOM_SALIN_0","HYCOM_DIR_0",
#                 "HYCOM_MAG_0",
#                 "HYCOM_UPVEL_50","FrontDist_Cayula",
#                 "EddyDist","Neg_EddyDist", "PosEddyDist",
#                 "DayOfYear","fac1","fac2")

transformList <- c("none","none","log10","log10",
                   "none","none",
                   "log10",
                   "none","log10",
                   "none","none","none",
                   "none","none","none")

transformedCovars.train <-
  transform.covars(mergedTrain.set2,covarList2,transformList)
transformedCovars.test <- 
  transform.covars(mergedTest.set2,covarList2,transformList)

transformedCovars_AcOnly.train <-
  transform.covars(Train_AcOnly.set2,covarList2,transformList)
transformedCovars_AcOnly.test <-
  transform.covars(Test_AcOnly.set2,covarList2,transformList)
transformedCovars_VisOnly.train <-
  transform.covars(Train_VisOnly.set2,covarList2,transformList)
transformedCovars_VisOnly.test <-
  transform.covars(Test_VisOnly.set2,covarList2,transformList)

# Generate correlation plots with transform
png(paste(outDir,SP,'_correlations_withTransform.png',sep=''), width = 2000, height = 1600)
pairs.panels(transformedCovars.train[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off() 
png(paste(outDir,SP,'_correlations_withTransform_AcOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(transformedCovars_AcOnly.train[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off() 
png(paste(outDir,SP,'_correlations_withTransform_visOnly.png',sep=''), width = 2000, height = 1600)
pairs.panels(transformedCovars_VisOnly.train[,1:(length(covarList2)-2)], ellipses=FALSE, method = "spearman",cex.cor=.75)
dev.off() 

```


```{r transformed dot plots, eval = TRUE, message = FALSE, results = 'hide', echo = FALSE}
# Plotting the transformed variables: 
plotCols = colnames(transformedCovars.train)[1:(length(covarList2)-2)]
plot.cleveland(transformedCovars.train,
               plotCols,TRUE,paste0(outDir,'AcousticAndVisual_',SP))
plot.cleveland(transformedCovars_AcOnly.train,
               plotCols,TRUE,paste0(outDir,'AcousticOnly_',SP))
plot.cleveland(transformedCovars_VisOnly.train,
               plotCols,TRUE,paste0(outDir,'VisualOnly_',SP))

```

Below, the two sets of covariates have been combined and transformed: 

![](E:/NASData/ModelData/Kspp/AcousticAndVisual_Kspp_clevelandDots_withTransform.png)

<br>

### 1.2.3 Check Predictors

To get an idea of the basic predictive power of these covariates, we can look at presence/absence relative to each variable. This also provides an opportunity to look at the range of values observed for each covariate in the visual and acoustic datasets. In the plots below dotted lines indicate the distribution of each covariate when animals were present, and solid lines indicate the distribution when animals were absent. Note that these plots do not account for effort.

```{r presence absence histograms, eval = TRUE, message = FALSE, results = 'hide', echo = FALSE}
plot.covarDensity(transformedCovars.train[,1:(length(transformedCovars.train)-2)],
                  colnames(transformedCovars.train[,1:(length(transformedCovars.train)-2)]),
                  mergedTrain.set$Density,paste0(outDir,'Both_',SP))

plot.covarDensity(transformedCovars_AcOnly.train[,1:(length(transformedCovars_AcOnly.train)-2)],
                   colnames(transformedCovars_AcOnly.train[1:(length(transformedCovars_AcOnly.train)-2)]),
                  Train_AcOnly.set$Density,paste0(outDir,'AcousticOnly_',SP))		

plot.covarDensity(transformedCovars_VisOnly.train[,1:(length(transformedCovars_VisOnly.train)-2)],
                  colnames(transformedCovars_VisOnly.train[,1:(length(transformedCovars_VisOnly.train)-2)]),
                  Train_VisOnly.set$Density,paste0(outDir,'VisualOnly_',SP))
```

<br> 

**Acoustic kernel densities:**

![](E:/NASData/ModelData/Kspp/AcousticOnly_Kspp_density_pres_abs.png)

<br>  
**Visual kernel densities:**

![](E:/NASData/ModelData/Kspp/VisualOnly_Kspp_density_pres_abs.png)

<br>  

<br>  

### 1.2.4 Estimate Relative Weights


<br>

Currently, weights are based on the following logic: 

* Acoustic data represent presence in 1 day bins, 

* Acoustic data have a trucation distance  of 0.7km for kogia(95% of group detections occur within this range), for a total monitoring area of $(0.7 km)^{2} \pi$, 

* Visual data represent presence during ~10 km transect segments traveling at ~10 knots or ~18.5km/hr. Therefore each visual datapoint represents ~0.54 hours of effort. 

* Visual trucation distance for kogia is estimated as 4km (see figure below) from these data. ESW is multiplied by transect segment length (usually ~10km) and doubled to estimate total area swept.


<br>  

\[\text{Acoustic to Visual ratio} = \frac{24 hrs \cdot (.7 km)^{2} \pi}{(\text{Segment length}/18.52 km/hr) \cdot \text{ESW} \cdot \text{Segment length} \cdot 2} = 0.8553 \approx 0.86:1
\]

<br> 

**Best visual detection probability model:**

![](E:/NASData/ModelData/Kspp/KsppsightwTrunc_GU.png)

<br> 

Zeros in visual dataset are down-weighted by g0 for this species, as estimated by Palka 2007.


```{r Calculate weights, echo = FALSE, eval = TRUE}
# VisOnly Case

cat(paste0('Mean visual data point weight: ', 
           round(mean(Train_VisOnly.set$Weight)), 
           '\nAcoustic data point weight: ',
           round(mean(Train_AcOnly.set$Weight))))

```

<br> 

# 2. Model Fitting

Models were fit using avNNet from the caret package in R. 

```{r load starting data, echo = FALSE} 
pOccur <- read.csv(pOccurenceFile, header = TRUE,na.strings=c('',' ','NA','NaN'))
```

```{r model setup, echo = FALSE} 
yAcOnly <- Train_AcOnly.set$Density
yVisOnly <- Train_VisOnly.set$Density
y <- mergedTrain.set$Density

load("E:/NASData/ModelData/Kspp/KsppsightwTrunc_GU.Rdata")
visDetProb <- detFun[[bestModelIdx]]$fitted[1]

transformedCovars_AcOnly.train$yAcOnly_TF<-(Train_AcOnly.set$Density >0)*1
transformedCovars_VisOnly.train$yVisOnly_TF<-(Train_VisOnly.set$Density >0)*1
transformedCovars.train$y_TF<-(mergedTrain.set$Density>0)*1

transformedCovars_AcOnly.test$yAcOnly_TF<-(Test_AcOnly.set$Density >0)*1
transformedCovars_VisOnly.test$yVisOnly_TF<-(Test_VisOnly.set$Density >0)*1
transformedCovars.test$y_TF<- (mergedTest.set$Density>0)*1

# make some factors and calculate introduce column of g0 weights
joint_train_weightsG0<- array(data = 1, dim = c(length(transformedCovars.train$fac1),1))
joint_test_weightsG0<- array(data = 1, dim = c(length(transformedCovars.train$fac1),1))


for (iFac in 1:length(transformedCovars.train$fac1)) {
  if (!is.na(transformedCovars.train$fac1[iFac])){
    if (transformedCovars.train$fac1[iFac]>5) {
      if (mergedTrain.set$Density[iFac]==0){
        # if it's visual data and it's a zero, adjust by g0 ie, only a X% chance it was a true zero.
        joint_train_weightsG0[iFac,1] <- visG0
      }
    }
  }
}


for (iFac in 1:length(transformedCovars.test$fac1)) {
  if (!is.na(transformedCovars.test$fac1[iFac])){
    if (transformedCovars.test$fac1[iFac]>5) {
       if (mergedTest.set$Density[iFac]==0){
        # if it's visual data and it's a zero, adjust by g0 ie, only a X% chance it was a true zero.
        joint_test_weightsG0[iFac,1] <- visG0*visDetProb
      }
    }
  }
}

VisOnly.train_weightsG0<- array(data = 1, dim = c(length(transformedCovars_VisOnly.train$fac1),1))
VisOnly.test_weightsG0<- array(data = 1, dim = c(length(transformedCovars_VisOnly.train$fac1),1))

for (iFac in 1:length(transformedCovars_VisOnly.train$fac1)) {
  if (Train_VisOnly.set$Density[iFac]==0){
    # if it's visual data and it's a zero, adjust by g0 ie, only a X% chance it was a true zero.
    VisOnly.train_weightsG0[iFac,1] <- visG0*visDetProb
  }
}

for (iFac in 1:length(transformedCovars_VisOnly.test$fac1)) {
  if (Test_VisOnly.set$Density[iFac]==0){
    # if it's visual data and it's a zero, adjust by g0 ie, only a X% chance it was a true zero.
    VisOnly.test_weightsG0[iFac,1] <- visG0*visDetProb
  }
}

# Remove NaNs
goodData_Ac <- which(!is.na(rowSums(transformedCovars_AcOnly.train)))
AcOnly.train.NoNa <- transformedCovars_AcOnly.train[goodData_Ac,]

goodData_Vis <- which(!is.na(rowSums(transformedCovars_VisOnly.train)))
VisOnly.train.NoNa <- transformedCovars_VisOnly.train[goodData_Vis,]

goodData_Joint <- which(!is.na(rowSums(transformedCovars.train)))
Joint.train.NoNa <- transformedCovars.train[goodData_Joint,]


goodData_Ac_test <- which(!is.na(rowSums(transformedCovars_AcOnly.test)))
AcOnly.test.NoNa <- transformedCovars_AcOnly.test[goodData_Ac_test,]

goodData_Vis_test <- which(!is.na(rowSums(transformedCovars_VisOnly.test)))
VisOnly.test.NoNa <- transformedCovars_VisOnly.test[goodData_Vis_test,]

goodData_Joint_test <- which(!is.na(rowSums(transformedCovars.test)))
Joint.test.NoNa <- transformedCovars.test[goodData_Joint_test,]

```

```{r Scale all the data, echo = FALSE}
# NNs don't do well with unscaled data. Scale it and then unscale it at the end.

# Scale Ac only training data for the NN
covars_AcOnly_max.train <- apply(AcOnly.train.NoNa, 2, max, na.rm = TRUE) 
covars_AcOnly_min.train <- apply(AcOnly.train.NoNa, 2, min, na.rm = TRUE)
AcOnly_train_scaled <- as.data.frame(scale(AcOnly.train.NoNa, 
                          center = covars_AcOnly_min.train, 
                          scale = covars_AcOnly_max.train-covars_AcOnly_min.train))

# Scale Vis only training data for the NN
covars_VisOnly_max.train <- apply(VisOnly.train.NoNa, 2, max, na.rm = TRUE) 
covars_VisOnly_min.train <- apply(VisOnly.train.NoNa, 2, min, na.rm = TRUE)
VisOnly_train_scaled <- as.data.frame(scale(VisOnly.train.NoNa, 
                            center = covars_VisOnly_min.train, 
                            scale = covars_VisOnly_max.train-covars_VisOnly_min.train))
VisOnly_train_scaled$weightsG0<-VisOnly.train_weightsG0[goodData_Vis]

# Scale Joint training data for the NN
covars_Joint_max.train <- apply(Joint.train.NoNa, 2, max, na.rm = TRUE) 
covars_Joint_min.train <- apply(Joint.train.NoNa, 2, min, na.rm = TRUE)
Joint_train_scaled <- as.data.frame(scale(Joint.train.NoNa, 
                        center = covars_Joint_min.train, 
                        scale = covars_Joint_max.train-covars_Joint_min.train))

Joint_train_scaled$weightsG0<-joint_train_weightsG0[goodData_Joint]*
                                (mergedTrain.set$Weight[goodData_Joint]/
                                max(mergedTrain.set$Weight[goodData_Joint]))

# Scale Ac only test data for the NN
covars_AcOnly_max.test <- apply(AcOnly.test.NoNa, 2, max, na.rm = TRUE) 
covars_AcOnly_min.test <- apply(AcOnly.test.NoNa, 2, min, na.rm = TRUE)
AcOnly_test_scaled <- as.data.frame(scale(AcOnly.test.NoNa, 
                       center = covars_AcOnly_min.test,
                       scale = covars_AcOnly_max.test-covars_AcOnly_min.test))

# Scale Vis only test data for the NN
covars_VisOnly_max.test <- apply(VisOnly.test.NoNa, 2, max, na.rm = TRUE) 
covars_VisOnly_min.test <- apply(VisOnly.test.NoNa, 2, min, na.rm = TRUE)
VisOnly_test_scaled <- as.data.frame(scale(VisOnly.test.NoNa, 
                         center = covars_VisOnly_min.test, 
                         scale = covars_VisOnly_max.test-covars_VisOnly_min.test))
VisOnly_test_scaled$weightsG0<-VisOnly.test_weightsG0[goodData_Vis_test]


# Scale Joint test data for the NN
covars_Joint_max.test <- apply(Joint.test.NoNa, 2, max, na.rm = TRUE) 
covars_Joint_min.test <- apply(Joint.test.NoNa, 2, min, na.rm = TRUE)
Joint_test_scaled <- as.data.frame(scale(Joint.test.NoNa, 
                        center = covars_Joint_min.test, 
                        scale = covars_Joint_max.test-covars_Joint_min.test))
Joint_test_scaled$weightsG0<-joint_test_weightsG0[goodData_Joint_test]
n <- names(Joint_test_scaled)

```

<br> 

## 2.1 Run Models 

Run NNs Acoustic only, Visual only, and joint Acoustic/Visual datasets.

Models have the following characteristics: 

* 50 averaged repeats with random node initalization

* Include 8 covariates 

* One hidden layer 

* Weighted training data 

* Hidden node layer sizes from 2 to 14 were tested in 2 node increments to search for optimal network size. 
 
<br>


```{r, echo = FALSE}
model1.indices <- c(1:5,7,8,10)
nMax1 <- length(model1.indices)

layerSizeList <- seq(1,13,2)

# initialize empty structure for model storage
nn_AcOnly<-NULL
nn_VisOnly<-NULL
nn_Joint<-NULL

# initialize empty structure for error scores and predictions
MSE.nn_AcOnly_train<-NULL
MSE.nn_VisOnly_train<-NULL
MSE.nn_Joint_train<-NULL
MSE.nn_AcOnly_test<-NULL
MSE.nn_VisOnly_test<-NULL
MSE.nn_Joint_test<-NULL

pr.nn_AcOnly_train <- NULL
pr.nn_VisOnly_train <- NULL
pr.nn_Joint_train <- NULL
pr.nn_AcOnly_test <- NULL
pr.nn_VisOnly_test<- NULL
pr.nn_Joint_test <- NULL

trainRepeats <- 50

```

```{r Set up parallel cluster, eval = FALSE, echo = FALSE}
numCores <- detectCores() - 2
cl <-makeCluster(numCores)
```

```{r Ac. only Model 1, results = 'hide', message = FALSE, eval = FALSE, echo = TRUE}
## ACOUSTIC ONLY
AcCounter <- 0
f.AcOnly_NN1 <- as.formula(paste("yAcOnly_TF ~", paste(n[model1.indices], collapse = " + ")))
# Iterate over a range of hidden layer sizes between 2 and 14 nodes.

for (layerSize in layerSizeList){
  AcCounter <- AcCounter + 1  
  # put together the formula
  # train network
  nn_AcOnly[[AcCounter]] <- avNNet(f.AcOnly_NN1, data=AcOnly_train_scaled, 
                                 size = layerSize, 
                                 repeats = trainRepeats,
                                 na.action = na.omit,
                                 rang = 0.7, 
                                 decay = 0.0001, 
                                 maxit = 1000,
                                 trace = FALSE)
  
  # predict on train data and estimate Mean Squared Error (MSE)
  pr.nn_AcOnly_train[[AcCounter]] <- predict(nn_AcOnly[[AcCounter]],AcOnly_train_scaled[,model1.indices])
  MSE.nn_AcOnly_train[[AcCounter]] <- sum((AcOnly_train_scaled$yAcOnly_TF - 
                                    pr.nn_AcOnly_train[[AcCounter]])^2)/nrow(AcOnly_train_scaled[model1.indices])
  # predict on test data and estimate MSE
  pr.nn_AcOnly_test[[AcCounter]] <- predict(nn_AcOnly[[AcCounter]],AcOnly_test_scaled[,model1.indices])
  MSE.nn_AcOnly_test[[AcCounter]] <- sum((AcOnly_test_scaled$yAcOnly_TF - 
                                   pr.nn_AcOnly_test[[AcCounter]])^2)/nrow(AcOnly_test_scaled[model1.indices])
  cat(paste("Done with AcOnly model iteration ",AcCounter, " of ", length(layerSizeList),": Layer Size = ", layerSize, "\n"))

}
```



```{r other models 1, eval = FALSE, echo = TRUE} 
## VISUAL ONLY
modelCounter <- 0
# put together the formula
f.VisOnly_NN1 <- as.formula(paste("yVisOnly_TF ~", paste(n[model1.indices], collapse = " + ")))
f.Joint_NN1 <- as.formula(paste("y_TF ~", paste(n[model1.indices], collapse = " + ")))
for (layerSize in layerSizeList){
  modelCounter <- modelCounter + 1  
  # train network
  nn_VisOnly[[modelCounter]] <- avNNet(f.VisOnly_NN1, VisOnly_train_scaled,
                                       weights = VisOnly_train_scaled$weightsG0,  
                                       size = layerSize, 
                                       repeats = trainRepeats,
                                       na.action = na.omit,
                                       rang = 0.7,  
                                       decay = 0.0001, 
                                       maxit = 10000,
                                       trace = FALSE)
                                       # weights = 
  
  # predict on train data and estimate MSE
  pr.nn_VisOnly_train[[modelCounter]] <- predict(nn_VisOnly[[modelCounter]],VisOnly_train_scaled[,model1.indices])
  MSE.nn_VisOnly_train[[modelCounter]] <- sum(VisOnly_train_scaled$weightsG0*
                                                (VisOnly_train_scaled$yVisOnly_TF - 
                                                pr.nn_VisOnly_train[[modelCounter]])^2)/
                                                nrow(VisOnly_train_scaled[model1.indices])
  
  # predict on test data and estimate MSE
  pr.nn_VisOnly_test[[modelCounter]] <- predict(nn_VisOnly[[modelCounter]],VisOnly_test_scaled[,model1.indices])
  MSE.nn_VisOnly_test[[modelCounter]] <- sum(VisOnly_test_scaled$weightsG0*
                                               (VisOnly_test_scaled$yVisOnly_TF - 
                                                pr.nn_VisOnly_test[[modelCounter]])^2)/
                                                nrow(VisOnly_test_scaled[model1.indices])
  
  
  ## JOINT
  nn_Joint[[modelCounter]]  <- avNNet(f.Joint_NN1, Joint_train_scaled,
                                      weights = Joint_train_scaled$weightsG0,
                                      size = layerSize, 
                                      repeats = trainRepeats, 
                                      na.action = na.omit,
                                      rang = 0.7,  
                                      decay = 0.0001, 
                                      maxit = 10000,
                                      trace = FALSE)                                     

  
  pr.nn_Joint_train[[modelCounter]]  <- predict(nn_Joint[[modelCounter]] ,Joint_train_scaled[,model1.indices],na.action=na.omit)
  MSE.nn_Joint_train[[modelCounter]]  <- sum(Joint_train_scaled$weightsG0*(Joint_train_scaled$y_TF - 
                                                pr.nn_Joint_train[[modelCounter]])^2)/
                                                nrow(Joint_train_scaled[model1.indices])
  
  pr.nn_Joint_test[[modelCounter]]  <- predict(nn_Joint[[modelCounter]],Joint_test_scaled[,model1.indices],na.action=na.omit)
  MSE.nn_Joint_test[[modelCounter]]  <- sum(Joint_test_scaled$weightsG0*(Joint_test_scaled$y_TF - 
                                               pr.nn_Joint_test[[modelCounter]])^2)/
                                               nrow(Joint_test_scaled[model1.indices])
  cat(paste("Done with VisOnly and Joint model iteration ",modelCounter, " of ", length(layerSizeList),": Layer Size = ", layerSize, "\n"))
}
```

```{r Turn off parallel cluster, eval = FALSE, echo = FALSE}
stopCluster(cl)
```
<br>  


```{r save models, eval = FALSE, echo = FALSE}
# Save models if re-calculating everything
save(nn_AcOnly,MSE.nn_AcOnly_train,MSE.nn_AcOnly_test,
     pr.nn_AcOnly_train,pr.nn_AcOnly_test,
     file = paste(outDir,SP,'_AcOnly_NN.Rdata',sep=''))
save(nn_VisOnly,MSE.nn_VisOnly_train,MSE.nn_VisOnly_test,
     pr.nn_VisOnly_train,pr.nn_VisOnly_test,
     file = paste(outDir,SP,'_VisOnly_NN.Rdata',sep=''))
save(nn_Joint,MSE.nn_Joint_train,MSE.nn_Joint_test,
     pr.nn_Joint_train,pr.nn_Joint_test,
     file = paste(outDir,SP,'_Joint_NN.Rdata',sep=''))
```

```{r load models, eval = TRUE, echo = FALSE}
# alternative if models are already calculated
load(paste(outDir,SP,'_AcOnly_NN.Rdata',sep=''))
load(paste(outDir,SP,'_VisOnly_NN.Rdata',sep=''))
load(paste(outDir,SP,'_Joint_NN.Rdata',sep=''))
```

<br>

## 2.2 Model Comparisons

Models were compared using a Kolmogorov-Smirnov test to compare predicted and observed presence/absence in the test data.


```{r Model comparison, echo = FALSE}

XEntropy.AcOnly_train <- NULL
XEntropy.AcOnly_test <- NULL
XEntropy.VisOnly_train <- NULL
XEntropy.VisOnly_test <- NULL
XEntropy.Joint_train <- NULL
XEntropy.Joint_test <- NULL
for (iM in 1: length(nn_AcOnly)){
  XEntropy.AcOnly_train[[iM]] <- LogLoss(round(pr.nn_AcOnly_train[[iM]],digits = 0),AcOnly_train_scaled$yAcOnly_TF)
  XEntropy.AcOnly_test[[iM]] <- LogLoss(round(pr.nn_AcOnly_test[[iM]],digits = 0),AcOnly_test_scaled$yAcOnly_TF)
  XEntropy.VisOnly_train[[iM]] <- weighted_logloss(round(pr.nn_VisOnly_train[[iM]],
                                         digits = 0),VisOnly_train_scaled$yVisOnly_TF,
                                         VisOnly_train_scaled$weightsG0)
  XEntropy.VisOnly_test[[iM]] <- weighted_logloss(round(pr.nn_VisOnly_test[[iM]],digits = 0),
                                         VisOnly_test_scaled$yVisOnly_TF,
                                         VisOnly_test_scaled$weightsG0)
  XEntropy.Joint_train[[iM]] <- weighted_logloss(round(pr.nn_Joint_train[[iM]], digits = 0),
                                         Joint_train_scaled$y_TF,
                                         Joint_train_scaled$weightsG0)
  XEntropy.Joint_test[[iM]] <- weighted_logloss(round(pr.nn_Joint_test[[iM]], digits = 0),
                                         Joint_test_scaled$y_TF,
                                         Joint_test_scaled$weightsG0)
}

KSStat.AcOnly_train <- NULL
KSStat.AcOnly_test <- NULL
KSStat.VisOnly_train <- NULL
KSStat.VisOnly_test <- NULL
KSStat.Joint_train <- NULL
KSStat.Joint_test <- NULL
for (iM in 1: length(nn_AcOnly)){
  KSStat.AcOnly_train[[iM]] <- KS_Stat(round(pr.nn_AcOnly_train[[iM]],digits = 0),AcOnly_train_scaled$yAcOnly_TF)
  KSStat.AcOnly_test[[iM]] <- KS_Stat(round(pr.nn_AcOnly_test[[iM]],digits = 0),AcOnly_test_scaled$yAcOnly_TF)
  KSStat.VisOnly_train[[iM]] <- KS_Stat(round(pr.nn_VisOnly_train[[iM]],digits = 0),VisOnly_train_scaled$yVisOnly_TF)
  KSStat.VisOnly_test[[iM]] <- KS_Stat(round(pr.nn_VisOnly_test[[iM]],digits = 0),VisOnly_test_scaled$yVisOnly_TF)
  KSStat.Joint_train[[iM]] <- KS_Stat(round(pr.nn_Joint_train[[iM]],digits = 0),Joint_train_scaled$y_TF)
  KSStat.Joint_test[[iM]] <- KS_Stat(round(pr.nn_Joint_test[[iM]],digits = 0),Joint_test_scaled$y_TF)
}


# MSEtable<- rbind(MSE.nn_AcOnly_train,MSE.nn_AcOnly_test,MSE.nn_VisOnly_train,
#                  MSE.nn_VisOnly_test,MSE.nn_Joint_train,MSE.nn_Joint_test)
# colnames(MSEtable)<- layerSizeList
# rownames(MSEtable)<- c("Acoustic - Train","Acoustic - Test",
#                        "Visual - Train","Visual - Test",
#                        "Joint - Train","Joint - Test")
# 
# print('mean squared error scores (lower is better)')
# print(MSEtable, digits = 2)
# 
# 
XEntropyTable<- rbind(XEntropy.AcOnly_train,XEntropy.AcOnly_test,XEntropy.VisOnly_train,
                 XEntropy.VisOnly_test,XEntropy.Joint_train,XEntropy.Joint_test)

colnames(XEntropyTable)<- layerSizeList
rownames(XEntropyTable)<- c("Acoustic - Train","Acoustic - Test",
                       "Visual - Train","Visual - Test",
                       "Joint - Train","Joint - Test")
print('cross entropy scores (lower is better)')
print(round(XEntropyTable, digits = 2))


# KSStatTable<- rbind(KSStat.AcOnly_train,KSStat.AcOnly_test,KSStat.VisOnly_train,
#                  KSStat.VisOnly_test,KSStat.Joint_train,KSStat.Joint_test)
# 
# colnames(KSStatTable)<- layerSizeList
# rownames(KSStatTable)<- c("Acoustic - Train","Acoustic - Test",
#                        "Visual - Train","Visual - Test",
#                        "Joint - Train","Joint - Test")
# print('KS statistic (higher is better)')
# print(KSStatTable, digits = 2)
```


```{r best model index, echo = FALSE}
best_AcOnly_ModelIndex <-1
best_VisOnly_ModelIndex <-1
best_Joint_ModelIndex <-6

```

<br> 

## 2.3 Variable Importance

For the best model in each category, the importance of each input variable was calculated across the 50 model iterations.

```{r, Variable Importance, echo = FALSE, eval = TRUE}
Ac_importance_avg <-varImp(nn_AcOnly[[best_AcOnly_ModelIndex]])
Vis_importance_avg <-varImp(nn_VisOnly[[best_VisOnly_ModelIndex]])
Joint_importance_avg <-varImp(nn_Joint[[best_Joint_ModelIndex]])

AcOnly_node_mean<-NULL
AcOnly_node_cv<-NULL
VisOnly_node_mean<-NULL
VisOnly_node_cv<-NULL
Joint_node_mean<-NULL
Joint_node_cv<-NULL

for (iNode in 1:length(model1.indices)) {
  thisSet <- (1:trainRepeats)+(trainRepeats*(iNode-1))
  
  AcOnly_node_mean[iNode] <- mean(Ac_importance_avg$Overall[thisSet])
  AcOnly_node_cv[iNode] <- std(Ac_importance_avg$Overall[thisSet])/mean(Ac_importance_avg$Overall[thisSet])

  VisOnly_node_mean[iNode] <- mean(Vis_importance_avg$Overall[thisSet])
  VisOnly_node_cv[iNode] <- std(Vis_importance_avg$Overall[thisSet])/mean(Vis_importance_avg$Overall[thisSet])
  
  Joint_node_mean[iNode] <- mean(Joint_importance_avg$Overall[thisSet])
  Joint_node_cv[iNode] <- std(Joint_importance_avg$Overall[thisSet])/mean(Joint_importance_avg$Overall[thisSet])
}
mean_var_importance<-NULL
mean_var_importance$AcOnly <- AcOnly_node_mean
mean_var_importance$VisOnly <- VisOnly_node_mean
mean_var_importance$Joint <- Joint_node_mean
mean_var_importance<-as.data.frame(mean_var_importance)
row.names(mean_var_importance)<-n[model1.indices]

kable(mean_var_importance,'markdown',digits = 1)
```

```{r plot network, message = FALSE, warning = FALSE, results = 'hide', echo = FALSE, fig.width = 14, fig.height = 8}

n2 = c('SST','SSH','CHL','MLD','SAL','CURRENT','UPWELLING','EDDY')
  png(paste(outDir,SP,'_exampleNetwork.png',sep=''), width = 1400, height = 800)
plot.nnet(nn_Joint[[best_Joint_ModelIndex]]$model[[1]],x.lab = n2, y.lab = "P(encounter)",bias = F,cex.val=2)
dev.off()
```
***Example network:***

![](E:/NASData/ModelData/Kspp/Kspp_exampleNetwork.png)

<br> 

# 3. Predict on Test Data

## 3.1 Temporal prediction

Predictions were made on the acoustic test dataset, and compared with actual observations for 2013. The predicted probabliity of encountering animals was compared with the actual weekly rate of occurrence of animals at a site. 

CAVEAT: Encounter probability from the data is estimated as fraction of days per week during which this species was detected. 


<br>

### 3.1.1 Acoustic Only Prediction


```{r Ac Temporal Predict, echo = FALSE, warning = FALSE, message = FALSE}
# Predict on acoustic test data, using acoustic only model for comparison...
compAcSet_MC <- which((AcOnly.test.NoNa$fac2)==5)
compAcSet_GC <- which((AcOnly.test.NoNa$fac2)==10)
compAcSet_DT <- which((AcOnly.test.NoNa$fac2)==15 |
                        (AcOnly.test.NoNa$fac2)==16)

# Predict in time
dateTicks = as.POSIXct(c('2013-01-01 GMT','2013-04-01 GMT',
                         '2013-07-01 GMT','2013-10-01 GMT',
                         '2014-01-01 GMT'))
dateLabels = c('Jan. 2013','Apr. 2013','Jul. 2013','Oct 2013','Jan. 2014')

predAcOnly_MC <- predict(nn_AcOnly[[best_AcOnly_ModelIndex]],AcOnly_test_scaled[compAcSet_MC,model1.indices])
predAcOnly_GC <- predict(nn_AcOnly[[best_AcOnly_ModelIndex]],AcOnly_test_scaled[compAcSet_GC,model1.indices])
predAcOnly_DT <- predict(nn_AcOnly[[best_AcOnly_ModelIndex]],AcOnly_test_scaled[compAcSet_DT,model1.indices])

occurIdx = which(as.POSIXct(pOccur[,1])>='2013-01-01' & as.POSIXct(pOccur[,1])<'2014-01-01')


AcOnly_predictionSet <- data.frame(unique(Test_AcOnly.set$date))
colnames(AcOnly_predictionSet) <-"date"
AcOnly_predictionSet$MC <- NA
MC_times <- Test_AcOnly.set$date[compAcSet_MC]
m1 <- match(MC_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$MC[m1] <-predAcOnly_MC

AcOnly_predictionSet$GC <- NA
GC_times <- Test_AcOnly.set$date[compAcSet_GC]
m2 <- match(GC_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$GC[m2] <-predAcOnly_GC

AcOnly_predictionSet$DT <- NA
DT_times <- Test_AcOnly.set$date[compAcSet_DT]
m3 <- match(DT_times,AcOnly_predictionSet$date)
AcOnly_predictionSet$DT[m3] <-predAcOnly_DT

AcOnly_predictionSet$Legend <- "Predictions"

pOccur$Legend <- "Observations"
```

**Predicted and observed encounter probabilities at passive acoustic sites using the acoustic-only model (Site order: MC, GC, DT):**

```{r,fig.height = 10, fig.width = 7, message = FALSE, warning = FALSE, echo = FALSE}
# par(mfrow = c(5,1),oma=c(3,0,5,0)),colour="#000099",colour="#CC0000"
p1_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MC, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=MC, color = Legend)) +
  labs(y = "", x = "")+
  scale_color_manual("",values= c("gray48","#009999"))+
  theme(legend.position = c(0.9, 0.7))

p2_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = GC, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=GC, color = Legend))+
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p3_Ac <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DT, color = Legend))+
  geom_line(data = AcOnly_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual("",values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")


multiplot(p1_Ac, p2_Ac, p3_Ac, cols=1)

```
<br>

### 3.1.2 Visual Only Prediction

```{r Vis Temporal Predict, warning = FALSE, echo = FALSE}
# Confusing, but acoustic only predictors are passed in to since
# we're predicting on the acoustic timeseries.
predVisOnly_MC <- predict(nn_VisOnly[[best_VisOnly_ModelIndex]],AcOnly_test_scaled[compAcSet_MC,model1.indices])
predVisOnly_GC <- predict(nn_VisOnly[[best_VisOnly_ModelIndex]],AcOnly_test_scaled[compAcSet_GC,model1.indices])
predVisOnly_DT <- predict(nn_VisOnly[[best_VisOnly_ModelIndex]],AcOnly_test_scaled[compAcSet_DT,model1.indices])

VisOnly_predictionSet <- data.frame(unique(Test_AcOnly.set$date))
colnames(VisOnly_predictionSet) <-"date"
VisOnly_predictionSet$MC <- NA
m1 <- match(MC_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$MC[m1] <-predVisOnly_MC

VisOnly_predictionSet$GC <- NA
m2 <- match(GC_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$GC[m2] <-predVisOnly_GC

VisOnly_predictionSet$DT <- NA
m3 <- match(DT_times,VisOnly_predictionSet$date)
VisOnly_predictionSet$DT[m3] <-predVisOnly_DT

VisOnly_predictionSet$Legend <- "Predictions"
```

**Predicted and observed encounter probabilities at passive acoustic sites using the visual-only model (Site order: MC, GC, DT):**

```{r,fig.height = 10, fig.width = 7, message = FALSE, warning = FALSE, echo = FALSE}
# par(mfrow = c(5,1),oma=c(3,0,5,0)),colour="#000099",colour="#CC0000"
p1_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MC, color = Legend))+
  geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=MC, color = Legend)) +
  labs(y = "", x = "")+
  scale_color_manual(values= c("gray48","#009999"))+
  theme(legend.position = c(0.9, 0.7))

p2_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = GC, color = Legend))+
  geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=GC, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p3_Vis <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DT, color = Legend))+
  geom_line(data = VisOnly_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")


multiplot(p1_Vis, p2_Vis, p3_Vis, cols=1)

```

<br>

### 3.1.3 Joint Prediction

```{r Combo Temporal Predict,fig.height = 10, fig.width = 7, warning = FALSE, echo = FALSE}
# Confusing, but acoustic only predictors are passed in to since we're predicting on the acoustic timeseries.
pred_MC <- predict(nn_Joint[[best_Joint_ModelIndex]],AcOnly_test_scaled[compAcSet_MC,model1.indices])
pred_GC <- predict(nn_Joint[[best_Joint_ModelIndex]],AcOnly_test_scaled[compAcSet_GC,model1.indices])
pred_DT <- predict(nn_Joint[[best_Joint_ModelIndex]],AcOnly_test_scaled[compAcSet_DT,model1.indices])

Both_predictionSet <- data.frame(unique(Test_AcOnly.set$date))
colnames(Both_predictionSet) <-"date"
Both_predictionSet$MC <- NA
m1 <- match(MC_times,Both_predictionSet$date)
Both_predictionSet$MC[m1] <-pred_MC

Both_predictionSet$GC <- NA
m2 <- match(GC_times,Both_predictionSet$date)
Both_predictionSet$GC[m2] <-pred_GC

Both_predictionSet$DT <- NA
m3 <- match(DT_times,Both_predictionSet$date)
Both_predictionSet$DT[m3] <-pred_DT

Both_predictionSet$Legend <- "Predictions"
```

**Predicted and observed encounter probabilities at passive acoustic sites using the joint model (Site order: MC, GC, DT):**

```{r,fig.height = 10, fig.width = 7, message = FALSE, warning = FALSE, echo = FALSE}
# par(mfrow = c(5,1),oma=c(3,0,5,0)),colour="#000099",colour="#CC0000"
p1 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x = as.POSIXct(dateStr), y = MC, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x=date, y=MC, color = Legend)) +
  labs(y = "", x = "")+
  scale_color_manual(values= c("gray48","#009999"))+
  theme(legend.position = c(0.9, 0.7))

p2 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = GC, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x=date, y=GC, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "", x = "")+
  theme(legend.position="none")

p3 <- ggplot() +
  geom_line(data = pOccur[occurIdx,],
             aes(x =as.POSIXct(dateStr), y = DT, color = Legend))+
  geom_line(data = Both_predictionSet,
            aes(x=date, y=DT, color = Legend)) +
  scale_color_manual(values= c("gray48","#009999"))+
  labs(y = "Encounter probability", x = "")+
  theme(legend.position="none")

multiplot(p1, p2, p3, cols = 1)

```
<br>

## 3.2 Spatial Prediction

```{r Load rasters, eval = FALSE, warning = FALSE, echo = FALSE}
#Load in rasters for prediction periods (2009 winter and summer)
### this code only needs to be run to regenerate the raster stack.

predTemplate <-raster('E:/NASData/AcoustoVisualDE/Prediction_template/Predictiontemplate.tif')
SST_jan_2009 <- scale(resample(raster('E:/NASData/AcoustoVisualDE/SST/SST_jan_2009.tif'),
  predTemplate),center = covars_Joint_min.train[1],scale = 
  covars_Joint_max.train[1]-covars_Joint_min.train[1])
SST_july_2009 <- scale(resample(raster('E:/NASData/AcoustoVisualDE/SST/SST_july_2009.tif'),
  predTemplate),center = covars_Joint_min.train[1],scale = 
  covars_Joint_max.train[1]-covars_Joint_min.train[1])

SSH_jan_2009 <- scale(resample(raster('E:/NASData/AcoustoVisualDE/SSH/SSH_jan2009.tif'),
  predTemplate),center = covars_Joint_min.train[2],
  scale = covars_Joint_max.train[2]-covars_Joint_min.train[2])
SSH_july_2009 <- scale(resample(raster('E:/NASData/AcoustoVisualDE/SSH/SSH_july2009.tif'),
  predTemplate),center = covars_Joint_min.train[2],
  scale = covars_Joint_max.train[2]-covars_Joint_min.train[2])

log10_CHL_jan_2009 <- scale(log10(resample(raster('E:/NASData/AcoustoVisualDE/CHL/CHL_jan2009.tif'),
  predTemplate)),center = covars_Joint_min.train[3],scale = 
  covars_Joint_max.train[3]-covars_Joint_min.train[3])
log10_CHL_july_2009 <- scale(log10(resample(raster('E:/NASData/AcoustoVisualDE/CHL/CHL_july2009.tif'),
  predTemplate)),center = covars_Joint_min.train[3],scale = 
  covars_Joint_max.train[3]-covars_Joint_min.train[3])

log10_HYCOM_MLD_jan2009 <- scale( 
  resample(raster('E:/NASData/AcoustoVisualDE/MLD/log10_mld_jan2009.tif'),
  predTemplate),center = covars_Joint_min.train[4],
  scale = covars_Joint_max.train[4]-covars_Joint_min.train[4])
log10_HYCOM_MLD_july2009 <- scale(
  resample(raster('E:/NASData/AcoustoVisualDE/MLD/log10_mld_july2009.tif'),
  predTemplate),center = covars_Joint_min.train[4],
  scale = covars_Joint_max.train[4]-covars_Joint_min.train[4])

SAL_jan_2009 <- scale(resample(raster('E:/NASData/AcoustoVisualDE/Salinity/sal0_jan2009.tif'),
      predTemplate),center = covars_Joint_min.train[5],
      scale = covars_Joint_max.train[5]-covars_Joint_min.train[5])
SAL_july_2009 <- scale(resample(raster('E:/NASData/AcoustoVisualDE/Salinity/sal0_july2009.tif'),
      predTemplate),center = covars_Joint_min.train[5],
      scale = covars_Joint_max.train[5]-covars_Joint_min.train[5])

log10_HYCOM_MAG_0_jan2009 <- scale(
  resample(raster('E:/NASData/AcoustoVisualDE/HYCOM_Mag/log10_mag_jan2009.tif'),
  predTemplate),center = covars_Joint_min.train[7],
  scale = covars_Joint_max.train[7]-covars_Joint_min.train[7])
log10_HYCOM_MAG_0_july2009 <- scale(
  resample(raster('E:/NASData/AcoustoVisualDE/HYCOM_Mag/log10_mag_july2009.tif'),
  predTemplate),center = covars_Joint_min.train[7],
  scale = covars_Joint_max.train[7]-covars_Joint_min.train[7])

HYCOM_UPVEL_jan2009 <- scale( 
  resample(raster('E:/NASData/AcoustoVisualDE/HYCOM_UpVel/proj_HYCOM_upvel_50_jan09.tif'),
  predTemplate),center = covars_Joint_min.train[8],
  scale = covars_Joint_max.train[8]-covars_Joint_min.train[8])
HYCOM_UPVEL_july2009 <- scale(
  resample(raster('E:/NASData/AcoustoVisualDE/HYCOM_UpVel/proj_HYCOM_upvel_50_july09.tif'),
  predTemplate),center = covars_Joint_min.train[8],
  scale = covars_Joint_max.train[8]-covars_Joint_min.train[8])

log10_Cayula_jan_2009 <- 
  scale(resample(raster('E:/NASData/AcoustoVisualDE/Cayula/log10_CayulaFront_jan2009.tif'),
  predTemplate),center = covars_Joint_min.train[9],
  scale = covars_Joint_max.train[9]-covars_Joint_min.train[9])
log10_Cayula_july_2009 <- 
  scale(resample(raster('E:/NASData/AcoustoVisualDE/Cayula/log10_CayulaFront_july2009.tif'),
  predTemplate),center = covars_Joint_min.train[9],
  scale = covars_Joint_max.train[9]-covars_Joint_min.train[9])

Eddy_jan_2009 <- scale(resample(
  raster('E:/NASData/Eddy/JPL_ManualEddyDist/Climatologies/Projected/eddyDist_Jan_2009_proj.tif'),
  predTemplate),center = covars_Joint_min.train[10],
  scale = covars_Joint_max.train[10]-covars_Joint_min.train[10])
Eddy_july_2009 <- scale(resample(raster(
  'E:/NASData/Eddy/JPL_ManualEddyDist/Climatologies/Projected/eddyDist_July_2009_proj.tif'),
  predTemplate),center = covars_Joint_min.train[10],
  scale = covars_Joint_max.train[10]-covars_Joint_min.train[10])

Neg_Eddy_jan_2009 <- scale(resample(raster(
    'E:/NASData/AcoustoVisualDE/EddyDist/DistNegMSLA_eddy_polarities_2009015.img'),
  predTemplate),center = covars_Joint_min.train[11],
  scale = covars_Joint_max.train[11]-covars_Joint_min.train[11])
Neg_Eddy_july_2009 <- scale(resample(raster(
    'E:/NASData/AcoustoVisualDE/EddyDist/Neg_EddyDist_july2009.tif'),
    predTemplate),center = covars_Joint_min.train[11],
    scale = covars_Joint_max.train[11]-covars_Joint_min.train[11])

Pos_Eddy_july_2009 <- scale(
  resample(raster('E:/NASData/AcoustoVisualDE/EddyDist/PosEddyDist_Jul_2009.tif'),
  predTemplate),center = covars_Joint_min.train[12],
  scale = covars_Joint_max.train[12]-covars_Joint_min.train[12])
Pos_Eddy_jan_2009 <- scale(
  resample(raster('E:/NASData/AcoustoVisualDE/EddyDist/PosEddyDist_Jan_2009.tif'),
  predTemplate),center = covars_Joint_min.train[12],
  scale = covars_Joint_max.train[12]-covars_Joint_min.train[12])

```

```{r brick rasters, eval = FALSE, echo=FALSE}
jan2009_rasters <- brick(log10_CHL_jan_2009,SST_jan_2009,SSH_jan_2009,log10_Cayula_jan_2009,
                         SAL_jan_2009,Eddy_jan_2009,Neg_Eddy_jan_2009,Pos_Eddy_jan_2009,
                         log10_HYCOM_MAG_0_jan2009,log10_HYCOM_MLD_jan2009,HYCOM_UPVEL_jan2009) 

july2009_rasters <- brick(log10_CHL_july_2009,SST_july_2009,SSH_july_2009,log10_Cayula_july_2009,
                          SAL_july_2009,Eddy_july_2009,Neg_Eddy_july_2009,Pos_Eddy_july_2009,
                          log10_HYCOM_MAG_0_july2009,log10_HYCOM_MLD_july2009,HYCOM_UPVEL_july2009)      

names(jan2009_rasters)<-c('log10_CHL','SST','SSH','log10_FrontDist_Cayula',
                          'HYCOM_SALIN_0','EddyDist','Neg_EddyDist',"Pos_EddyDist",
                          'log10_HYCOM_MAG_0','log10_HYCOM_MLD','HYCOM_UPVEL_50')
names(july2009_rasters)<-c('log10_CHL','SST','SSH','log10_FrontDist_Cayula',
                         'HYCOM_SALIN_0','EddyDist','Neg_EddyDist',"Pos_EddyDist",
                         'log10_HYCOM_MAG_0','log10_HYCOM_MLD','HYCOM_UPVEL_50')

save(jan2009_rasters,july2009_rasters,
     file = 'E:/NASData/AcoustoVisualDE/AcoustoVisualDE/2009_prediction_rasters_scaled.Rdata')  
```


```{r load raster bricks, echo = FALSE}
load('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/2009_prediction_rasters_scaled.Rdata') 
```

Models were evaluated for summer (July 2009) and winter(January 2009) across the entire Gulf of Mexico (US EEZ beyond the 200m contour).

```{r Ac Spatial Predict, warning = FALSE, echo = FALSE}
### Acoustic Only spatial prediction

dt1 <- as.data.frame(jan2009_rasters,xy=TRUE)

jan2009_AcOnly_prediction <- raster::predict(jan2009_rasters,nn_AcOnly[[best_AcOnly_ModelIndex]],
                                             na.action = na.pass)
            
july2009_AcOnly_prediction <- raster::predict(july2009_rasters,nn_AcOnly[[best_AcOnly_ModelIndex]],na.action = na.pass) 

jan2009_AcOnly_prediction_probSee <- jan2009_AcOnly_prediction*visG0*visDetProb
july2009_AcOnly_prediction_probSee <- july2009_AcOnly_prediction*visG0*visDetProb

```


```{r Vis Spatial Predict, warning = FALSE, echo = FALSE}
### Visual Only spatial prediction
dt1 <- as.data.frame(jan2009_rasters,xy=TRUE)

jan2009_VisOnly_prediction <- raster::predict(jan2009_rasters,
         nn_VisOnly[[best_VisOnly_ModelIndex]],na.action = na.pass)
            
july2009_VisOnly_prediction <- raster::predict(july2009_rasters,
         nn_VisOnly[[best_VisOnly_ModelIndex]],na.action = na.pass)    

jan2009_VisOnly_prediction_probSee <- jan2009_VisOnly_prediction*visG0*visDetProb
july2009_VisOnly_prediction_probSee <- july2009_VisOnly_prediction*visG0*visDetProb

```


```{r Joint Spatial Predict, warning = FALSE, echo = FALSE}
### Joint Visual and Acoustic spatial prediction

dt1 <- as.data.frame(jan2009_rasters,xy=TRUE)

jan2009_prediction <- raster::predict(jan2009_rasters,
         nn_Joint[[best_Joint_ModelIndex]],na.action = na.pass)
            
july2009_prediction <- raster::predict(july2009_rasters,
         nn_Joint[[best_Joint_ModelIndex]],na.action = na.pass)    
```


```{r wrangle projections, message = FALSE, warning = FALSE, echo = FALSE, results = 'hide'}
# Wrangle projections for mapping:

predict_template <- readOGR('E:/NASData/AcoustoVisualDE/Prediction_template/prediction_polygon.shp')
map_proj <- sp::CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')
predict_template_proj <- spTransform(predict_template, CRSobj = map_proj)

# Acoustic
jan2009_AcOnly_prediction_proj <- projectRaster(jan2009_AcOnly_prediction, crs=map_proj)
july2009_AcOnly_prediction_proj <- projectRaster(july2009_AcOnly_prediction, crs=map_proj)
jan2009_AcOnly_prediction_crop <- mask(jan2009_AcOnly_prediction_proj,predict_template_proj)
july2009_AcOnly_prediction_crop <-
  mask(july2009_AcOnly_prediction_proj,predict_template_proj)
jan2009_AcOnly_map_probSee <- jan2009_AcOnly_prediction_crop*visG0*visDetProb
july2009_AcOnly_map_probSee <- july2009_AcOnly_prediction_crop*visG0*visDetProb


# Visual
jan2009_VisOnly_prediction_proj <- 
  projectRaster(jan2009_VisOnly_prediction, crs = map_proj)
july2009_VisOnly_prediction_proj <- 
  projectRaster(july2009_VisOnly_prediction, crs = map_proj)
#jan2009_VisOnly_prediction_SE_proj <- 
#  projectRaster(jan2009_VisOnly_prediction_SE, crs=map_proj)

jan2009_VisOnly_prediction_crop <- 
  mask(jan2009_VisOnly_prediction_proj,predict_template_proj)
july2009_VisOnly_prediction_crop <- mask(july2009_VisOnly_prediction_proj,predict_template_proj)
#jan2009_VisOnly_prediction_SE_crop <- mask(jan2009_VisOnly_prediction_SE_proj,predict_template_proj)
jan2009_VisOnly_map_probSee <- jan2009_VisOnly_prediction_crop*visG0*visDetProb
july2009_VisOnly_map_probSee <- july2009_VisOnly_prediction_crop*visG0*visDetProb

#Both
jan2009_prediction_proj <- projectRaster(jan2009_prediction, crs=map_proj)
july2009_prediction_proj <- projectRaster(july2009_prediction, crs=map_proj)
jan2009_prediction_crop <- mask(jan2009_prediction_proj,predict_template_proj)
july2009_prediction_crop <- mask(july2009_prediction_proj,predict_template_proj)
jan2009_map_probSee <- jan2009_prediction_crop*visG0*visDetProb
july2009_map_probSee <- july2009_prediction_crop*visG0*visDetProb
```
<br>

```{r Model Averaging, warning = FALSE, echo = FALSE}
### Model averaging 

# Alternatively, the visual and acoustic models could be averaged.

jan2009mean <- mean(jan2009_AcOnly_prediction_crop,jan2009_VisOnly_prediction_crop)
july2009mean <- mean(july2009_AcOnly_prediction_crop,july2009_VisOnly_prediction_crop)

jan2009mean_probSee <- july2009mean*visG0*visDetProb
july2009mean_probSee <- jan2009mean*visG0*visDetProb
```


**Summer 2009 predicted distribution and test sightings:**


```{r leaflet summer, message = FALSE, warning = FALSE, echo = FALSE}
# Display summer (July 2009) map:
maxColor <- ceiling(max(c(july2009_AcOnly_prediction_crop@data@max,
                july2009_VisOnly_prediction_crop@data@max,
                july2009_prediction_crop@data@max,
                july2009mean@data@max))*10)/10
pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,maxColor), 
                    na.color = 'transparent')
GU2009Effort = shapefile('E:/NASData/GU2009Effort/GU_Effort_Merge_clip.shp')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(july2009_AcOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Acoustic July 2009') %>%
  addRasterImage(july2009_VisOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Visual July 2009') %>%
  addRasterImage(july2009_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Joint July 2009') %>%
  addRasterImage(july2009mean,colors = pal,
                 opacity = 0.8, group = 'Vis. & Ac. Mean July 2009') %>% 
  addPolylines(data=GU2009Effort,group ='Visual Effort (Summer 2009)', opacity = 1,
               color = "black", weight = 2)%>%
  addCircleMarkers(data = sightingsTest, lng = ~ long, lat = ~ lat,color = "black",
                 stroke = TRUE, fillOpacity = 0.8,radius = 6,
                 group = 'Test Sightings (Summer 2009)') %>%
  addLegend(pal = pal, values = c(0,maxColor),
    title = 'P(encounter)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Acoustic July 2009','Visual July 2009',
                   'Joint July 2009','Vis. & Ac. Mean July 2009'),
    overlayGroups = c('Test Sightings (Summer 2009)', 'Visual Effort (Summer 2009)'),
    options = layersControlOptions(collapsed = FALSE)
  )
map

```

<br>  

**Summer 2009 predicted probability of sighting and test sightings:**


```{r leaflet summer sightings, message = FALSE, warning = FALSE, echo = FALSE}
# Display summer (July 2009) map:
maxColor <- ceiling(max(c(july2009_AcOnly_map_probSee@data@max,
                july2009_VisOnly_map_probSee@data@max,
                july2009_map_probSee@data@max,
                july2009mean_probSee@data@max))*10)/10
pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,maxColor), 
                    na.color = 'transparent')
GU2009Effort = shapefile('E:/NASData/GU2009Effort/GU_Effort_Merge_clip.shp')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(july2009_AcOnly_map_probSee, colors = pal,
                 opacity = 0.8, group = 'Acoustic July 2009') %>%
  addRasterImage(july2009_VisOnly_map_probSee, colors = pal,
                 opacity = 0.8, group = 'Visual July 2009') %>%
  addRasterImage(july2009_map_probSee, colors = pal,
                 opacity = 0.8, group = 'Joint July 2009') %>%
  addRasterImage(july2009mean_probSee,colors = pal,
                 opacity = 0.8, group = 'Vis. & Ac. Mean July 2009') %>% 
  addPolylines(data=GU2009Effort,group ='Visual Effort (Summer 2009)', opacity = 1,
               color = "black", weight = 2)%>%
  addCircleMarkers(data = sightingsTest, lng = ~ long, lat = ~ lat,color = "black",
                 stroke = TRUE, fillOpacity = 0.8,radius = 6,
                 group = 'Test Sightings (Summer 2009)') %>%
  addLegend(pal = pal, values = c(0,maxColor),
    title = 'P(sighting)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Acoustic July 2009','Visual July 2009',
                   'Joint July 2009','Vis. & Ac. Mean July 2009'),
    overlayGroups = c('Test Sightings (Summer 2009)', 'Visual Effort (Summer 2009)'),
    options = layersControlOptions(collapsed = FALSE)
  )
map
```

**Winter 2009 predicted distribution:**

```{r leaflet winter, message = FALSE, warning = FALSE, echo = FALSE}
# Display winter (January 2009) map:
maxColor <- ceiling(max(c(jan2009_AcOnly_prediction_crop@data@max,
                jan2009_VisOnly_prediction_crop@data@max,
                jan2009_prediction_crop@data@max,
                jan2009mean@data@max))*10)/10

pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,maxColor), 
                    na.color = 'transparent')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(jan2009_AcOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Acoustic Jan. 2009') %>%
  addRasterImage(jan2009_VisOnly_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Visual Jan. 2009') %>%
  addRasterImage(jan2009_prediction_crop, colors = pal,
                 opacity = 0.8, group = 'Joint Jan. 2009') %>%
  addRasterImage(jan2009mean,colors = pal,
                 opacity = 0.8, group = 'Vis. & Ac. Mean Jan. 2009') %>%
  addLegend(pal = pal, values = c(0,maxColor),
    title = 'P(encounter)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Acoustic Jan. 2009','Visual Jan. 2009',
                   'Joint Jan. 2009','Vis. & Ac. Mean Jan. 2009'),
    options = layersControlOptions(collapsed = FALSE)
  )
map

```


<br>

# 4. Monthly model predictions

Spatial model predictions were generated using oceanographic variables averaged by month between 2003 and 2015.


```{r evaluate climatology-based models, eval = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
load('E:/NASData/AcoustoVisualDE/AcoustoVisualDE/climatology_rasters_scaled.Rdata') 
monthNum <-c('01','02','03','04','05','06','07','08','09','10','11','12')
monthStr<-c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')

climatePrediction <- vector('list',length = 12)
mapClimatePrediction <- vector('list',length = 12)

for (iM in 1:length(monthStr)){
  climatePrediction[[iM]] <- raster::predict(raster_set[[iM]],nn_Joint[[best_Joint_ModelIndex]],
           na.action = na.pass)
  mapClimatePrediction[[iM]] <- mask(projectRaster(climatePrediction[[iM]], crs=map_proj),predict_template_proj)  
  # output raster to geotiff
  rasterImageFileName = paste0(savePath,'/climatology_predictions/', SP,'_',monthStr[iM],'NN_mean_encounter_probability.tif')
  writeRaster(mapClimatePrediction[[iM]],filename = rasterImageFileName, format="GTiff",overwrite = TRUE)
  
  #ouput raster to kml
  kmlImageFileName = paste0(savePath,'/climatology_predictions/', SP,'_',monthStr[iM],'NN_mean_encounter_probability.kml')
  KML(mapClimatePrediction[[iM]],file = kmlImageFileName, col=matlab.like2(32),overwrite = TRUE)
}
  
```

```{r plot climatologies, eval = FALSE, message = FALSE, warning = FALSE, echo = FALSE}
pal <- colorNumeric(palette = matlab.like2(5),
                    domain=c(0,1), 
                    na.color = 'transparent')

map <- leaflet(width="100%") %>%  setView(lng = -88.8, lat = 27.0, zoom = 6)%>%
  addProviderTiles(providers$Esri.OceanBasemap) %>%
  addRasterImage(mapClimatePrediction[[1]] , colors = pal,
                 opacity = 0.8, group = 'Jan.') %>%
  addRasterImage(mapClimatePrediction[[3]] , colors = pal,
                 opacity = 0.8, group = 'March') %>%
  addRasterImage(mapClimatePrediction[[5]] , colors = pal,
                 opacity = 0.8, group = 'May') %>%
  addRasterImage(mapClimatePrediction[[7]] , colors = pal,
                 opacity = 0.8, group = 'July') %>%
  addRasterImage(mapClimatePrediction[[9]] ,colors = pal,
                 opacity = 0.8, group = 'Sept.') %>%
  addRasterImage(mapClimatePrediction[[11]] ,colors = pal,
                 opacity = 0.8, group = 'Nov.') %>%
  addMarkers(data = HARPsites, lng = ~ long, lat = ~ lat,
             group = "HARP Locations") %>%
  addLegend(pal = pal, values = c(0,1),
    title = 'P(encounter)',position = "bottomleft") %>%
  addLayersControl(
    baseGroups = c('Jan.','March','May',
                   'July','Sept.','Nov.'),
    overlayGroups = c('HARP Locations'),
    options = layersControlOptions(collapsed = FALSE)
  )
map
```
